"""
è½¨è¿¹æ•°æ®é¢„å¤„ç†è„šæœ¬ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰

åŠŸèƒ½ï¼š
1. æ‰¹é‡è¯»å–åŸå§‹è½¨è¿¹CSVæ–‡ä»¶ï¼ˆæ— è¡¨å¤´æ ¼å¼ï¼‰
2. æ·»åŠ æ ‡å‡†åˆ—åï¼Œè§£ædatetimeæ ¼å¼
3. è‡ªåŠ¨æ£€æµ‹å¹¶åˆ†ç¦»å¤šè½¦è¾†æ–‡ä»¶ï¼ˆæŒ‰è½¦ç‰Œå·æ‹†åˆ†ï¼‰
4. ä½¿ç”¨å®Œæ•´è½¦ç‰Œå·ä½œä¸ºè½¦è¾†ID
5. ä½¿ç”¨ transbigdata è¿›è¡Œæ•°æ®æ¸…æ´—ï¼š
   - æ¸…ç†è¾¹ç•Œå¤–æ•°æ®ï¼ˆæ·±åœ³åŒºåŸŸï¼‰
   - æ¸…ç†å†—ä½™é‡å¤è®°å½•
   - æ¸…ç†æ¼‚ç§»å¼‚å¸¸ç‚¹ï¼ˆé€Ÿåº¦/è·ç¦»/è§’åº¦ï¼‰
6. æ”¯æŒå¹¶è¡Œå¤„ç†å¤šä¸ªæ–‡ä»¶
7. ä¿å­˜ä¸ºæ ‡å‡†CSVæ ¼å¼ï¼ˆæ¯ä¸ªè½¦è¾†ä¸€ä¸ªæ–‡ä»¶ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    åœ¨è„šæœ¬å†…éƒ¨ä¿®æ”¹CONFIGé…ç½®åç›´æ¥è¿è¡Œï¼š
    python preprocess_trajectories.py

é…ç½®è¯´æ˜ï¼š
    - input_dir: è¾“å…¥ç›®å½•
    - output_dir: è¾“å‡ºç›®å½•
    - parallel: True/False æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
    - n_workers: å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ˆNone=è‡ªåŠ¨æ£€æµ‹CPUæ ¸å¿ƒæ•°ï¼‰
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
import transbigdata as tbd
from concurrent.futures import ProcessPoolExecutor, as_completed
import os


# ==================== é…ç½®å‚æ•° ====================
CONFIG = {
    # è¾“å…¥ç›®å½•
    'input_dir': '../traj',

    # è¾“å‡ºç›®å½•
    'output_dir': '../traj',

    # å¹¶è¡Œå¤„ç†é…ç½®
    'parallel': True,           # æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
    'n_workers': 10             # å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ˆNone = è‡ªåŠ¨ä½¿ç”¨ CPU æ ¸å¿ƒæ•°ï¼‰
}
# =================================================


def preprocess_trajectory(input_path, output_dir='traj'):
    """
    é¢„å¤„ç†å•ä¸ªè½¨è¿¹æ–‡ä»¶ï¼Œè‡ªåŠ¨æ£€æµ‹å¹¶åˆ†ç¦»å¤šè½¦è¾†æ•°æ®

    Parameters
    ----------
    input_path : str or Path
        è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
    output_dir : str
        è¾“å‡ºç›®å½•

    Returns
    -------
    list of str
        å¤„ç†æˆåŠŸçš„è½¦è¾†IDåˆ—è¡¨
    """
    input_path = Path(input_path)

    print(f"\n{'='*60}")
    print(f"é¢„å¤„ç†è½¨è¿¹æ–‡ä»¶: {input_path.name}")
    print('='*60)

    # è¯»å–åŸå§‹CSVï¼ˆæ— è¡¨å¤´ï¼‰
    print("ğŸ“‚ è¯»å–åŸå§‹CSV...")
    df = pd.read_csv(input_path, header=None, names=[
        'datetime', 'vehicle_id', 'lng', 'lat',
        'speed', 'angle', 'operation_status'
    ])

    print(f"   åŸå§‹è®°å½•æ•°: {len(df):,}")

    # è§£ædatetime
    print("ğŸ• è§£ædatetimeæ ¼å¼...")
    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y%m%d%H%M%S')
    df['datetime'] = df['datetime'].dt.tz_localize('Asia/Shanghai')  # æ ‡è®°ä¸ºæ·±åœ³/ä¸­å›½æ—¶åŒº

    # æ£€æŸ¥è½¦è¾†IDå¹¶æŒ‰è½¦è¾†åˆ†ç»„å¤„ç†
    print("ğŸš— æ£€æŸ¥è½¦è¾†ID...")
    unique_raw_ids = df['vehicle_id'].unique()

    if len(unique_raw_ids) > 1:
        print(f"âš ï¸  å‘ç°å¤šä¸ªè½¦è¾†ID: {len(unique_raw_ids)} ä¸ªï¼Œå°†åˆ†åˆ«å¤„ç†")
    else:
        print(f"   è½¦è¾†ID: {unique_raw_ids[0]}")

    # ç»Ÿä¸€å¤„ç†ï¼šæŒ‰è½¦è¾†IDåˆ†ç»„å¤„ç†ï¼ˆæ— è®ºå•è½¦è¾†è¿˜æ˜¯å¤šè½¦è¾†ï¼‰
    all_results = []
    for idx, raw_vehicle_id in enumerate(unique_raw_ids, 1):
        vehicle_id = str(raw_vehicle_id)

        if len(unique_raw_ids) > 1:
            print(f"\n   --- å¤„ç†è½¦è¾† {idx}/{len(unique_raw_ids)}: {vehicle_id} ---")

        # è¿‡æ»¤å½“å‰è½¦è¾†çš„æ•°æ®
        vehicle_df = df[df['vehicle_id'] == raw_vehicle_id].copy()

        if len(unique_raw_ids) > 1:
            print(f"   è®°å½•æ•°: {len(vehicle_df):,}")

        # æ•°æ®æ¸…æ´—
        print("   âœ… æ•°æ®éªŒè¯...")

        # ä½¿ç”¨ transbigdata æ¸…ç†è¾¹ç•Œå¤–æ•°æ®ï¼ˆæ·±åœ³åŒºåŸŸï¼‰
        records_before = len(vehicle_df)
        vehicle_df = tbd.clean_outofbounds(
            vehicle_df,
            bounds=[113, 22, 115, 23],
            col=['lng', 'lat']
        )
        removed_coords = records_before - len(vehicle_df)
        if removed_coords > 0:
            print(f"      âš ï¸  [transbigdata] ç§»é™¤ {removed_coords} æ¡è¾¹ç•Œå¤–è®°å½•")

        # æ£€æŸ¥è§’åº¦èŒƒå›´
        invalid_angle = (vehicle_df['angle'] < 0) | (vehicle_df['angle'] > 359)
        if invalid_angle.sum() > 0:
            print(f"      âš ï¸  å‘ç° {invalid_angle.sum()} æ¡è§’åº¦å¼‚å¸¸è®°å½•")
            vehicle_df = vehicle_df[~invalid_angle]

        # ä½¿ç”¨ transbigdata æ¸…ç†é‡å¤è®°å½•
        records_before = len(vehicle_df)
        vehicle_df = tbd.traj_clean_redundant(
            vehicle_df,
            col=['vehicle_id', 'datetime', 'lng', 'lat']
        )
        removed_duplicates = records_before - len(vehicle_df)
        if removed_duplicates > 0:
            print(f"      âš ï¸  [transbigdata] ç§»é™¤ {removed_duplicates} æ¡å†—ä½™è®°å½•")

        # ä½¿ç”¨ transbigdata æ¸…ç†æ¼‚ç§»å¼‚å¸¸ç‚¹
        records_before = len(vehicle_df)
        vehicle_df = tbd.traj_clean_drift(
            vehicle_df,
            col=['vehicle_id', 'datetime', 'lng', 'lat'],
            speedlimit=100,
            dislimit=1000,
            anglelimit=30
        )
        removed_drift = records_before - len(vehicle_df)
        if removed_drift > 0:
            print(f"      âš ï¸  [transbigdata] ç§»é™¤ {removed_drift} æ¡æ¼‚ç§»å¼‚å¸¸ç‚¹")

        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'vehicle_id': vehicle_id,
            'raw_vehicle_id': raw_vehicle_id,
            'total_records': len(vehicle_df),
            'time_range': (vehicle_df['datetime'].min(), vehicle_df['datetime'].max()),
            'duration_hours': (vehicle_df['datetime'].max() - vehicle_df['datetime'].min()).total_seconds() / 3600,
            'avg_speed': vehicle_df['speed'].mean(),
            'coord_bounds': {
                'lng_min': vehicle_df['lng'].min(),
                'lng_max': vehicle_df['lng'].max(),
                'lat_min': vehicle_df['lat'].min(),
                'lat_max': vehicle_df['lat'].max()
            }
        }

        print(f"\n   ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"      æœ‰æ•ˆè®°å½•æ•°: {stats['total_records']:,}")
        print(f"      æ—¶é—´èŒƒå›´: {stats['time_range'][0]} è‡³ {stats['time_range'][1]}")
        print(f"      æŒç»­æ—¶é—´: {stats['duration_hours']:.2f} å°æ—¶")
        print(f"      å¹³å‡é€Ÿåº¦: {stats['avg_speed']:.1f} km/h")
        print(f"      ç»åº¦èŒƒå›´: {stats['coord_bounds']['lng_min']:.4f} ~ {stats['coord_bounds']['lng_max']:.4f}")
        print(f"      çº¬åº¦èŒƒå›´: {stats['coord_bounds']['lat_min']:.4f} ~ {stats['coord_bounds']['lat_max']:.4f}")

        # ä¿å­˜å¤„ç†åçš„CSV
        output_dir_path = Path(output_dir)
        output_dir_path.mkdir(parents=True, exist_ok=True)
        output_filename = f"{vehicle_id}_processed.csv"
        output_path = output_dir_path / output_filename

        vehicle_df.to_csv(output_path, index=False)
        file_size_mb = output_path.stat().st_size / (1024 * 1024)

        print(f"\n   ğŸ’¾ ä¿å­˜åˆ°: {output_path}")
        print(f"      æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")

        if len(unique_raw_ids) > 1:
            print('   ' + '='*60)

        all_results.append((vehicle_id, output_path, stats))

    if len(unique_raw_ids) > 1:
        print(f"\nâœ… å¤šè½¦è¾†æ–‡ä»¶æ‹†åˆ†å®Œæˆ: {len(all_results)} ä¸ªè½¦è¾†")

    print('='*60)

    # è¿”å›æ‰€æœ‰å¤„ç†æˆåŠŸçš„è½¦è¾†IDåˆ—è¡¨
    processed_vehicle_ids = [vid for vid, _, _ in all_results]
    print(f"\nâœ… å¤„ç†å®Œæˆï¼Œç”Ÿæˆè½¦è¾†: {', '.join(processed_vehicle_ids)}")

    return processed_vehicle_ids


def _process_single_file(args):
    """
    å•ä¸ªæ–‡ä»¶å¤„ç†çš„åŒ…è£…å‡½æ•°ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰

    Parameters
    ----------
    args : tuple
        (csv_file, output_dir)

    Returns
    -------
    list of str or None
        æˆåŠŸæ—¶è¿”å›è½¦è¾†IDåˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å› None
    """
    csv_file, output_dir = args
    try:
        vehicle_ids = preprocess_trajectory(csv_file, output_dir)
        return vehicle_ids
    except Exception as e:
        print(f"\nâŒ å¤„ç† {csv_file.name} å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def preprocess_all_trajectories(input_dir='traj', output_dir='traj', parallel=False, n_workers=None):
    """
    æ‰¹é‡é¢„å¤„ç†æ‰€æœ‰è½¨è¿¹æ–‡ä»¶

    Parameters
    ----------
    input_dir : str
        è¾“å…¥ç›®å½•
    output_dir : str
        è¾“å‡ºç›®å½•
    parallel : bool
        æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
    n_workers : int or None
        å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ˆNone = è‡ªåŠ¨ä½¿ç”¨ CPU æ ¸å¿ƒæ•°ï¼‰

    Returns
    -------
    list of str
        æ‰€æœ‰å¤„ç†æˆåŠŸçš„è½¦è¾†IDåˆ—è¡¨
    """
    input_dir = Path(input_dir)

    # æŸ¥æ‰¾æ‰€æœ‰åŸå§‹CSVæ–‡ä»¶ï¼ˆæ’é™¤å·²å¤„ç†çš„ï¼‰
    csv_files = list(input_dir.glob('*.csv'))
    csv_files = [f for f in csv_files if '_processed' not in f.name]

    if not csv_files:
        print("æœªæ‰¾åˆ°å¾…å¤„ç†çš„CSVæ–‡ä»¶")
        return []

    print(f"\n{'='*60}")
    print(f"æ‰¹é‡é¢„å¤„ç†è½¨è¿¹æ•°æ®")
    print('='*60)
    print(f"å‘ç° {len(csv_files)} ä¸ªå¾…å¤„ç†æ–‡ä»¶:")
    for f in csv_files:
        print(f"  - {f.name}")

    all_vehicle_ids = []

    if parallel and len(csv_files) > 1:
        # å¹¶è¡Œå¤„ç†æ¨¡å¼
        if n_workers is None:
            n_workers = os.cpu_count()
        print(f"\nğŸš€ å¯ç”¨å¹¶è¡Œå¤„ç†æ¨¡å¼ï¼ˆ{n_workers} ä¸ªå·¥ä½œè¿›ç¨‹ï¼‰")

        with ProcessPoolExecutor(max_workers=n_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(_process_single_file, (csv_file, output_dir)): csv_file
                for csv_file in csv_files
            }

            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(future_to_file):
                completed += 1
                result = future.result()
                if result is not None:
                    all_vehicle_ids.extend(result)  # æ·»åŠ æ‰€æœ‰è½¦è¾†ID
                print(f"   è¿›åº¦: {completed}/{len(csv_files)}")
    else:
        # ä¸²è¡Œå¤„ç†æ¨¡å¼
        if parallel:
            print(f"\nâš ï¸  æ–‡ä»¶æ•°é‡å°‘äº2ä¸ªï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†")
        else:
            print(f"\nğŸ“ ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼")

        for csv_file in csv_files:
            try:
                vehicle_ids = preprocess_trajectory(csv_file, output_dir)
                all_vehicle_ids.extend(vehicle_ids)  # æ·»åŠ æ‰€æœ‰è½¦è¾†ID
            except Exception as e:
                print(f"\nâŒ å¤„ç† {csv_file.name} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue

    # æ±‡æ€»æŠ¥å‘Š
    print(f"\n{'='*60}")
    print("é¢„å¤„ç†æ±‡æ€»")
    print('='*60)
    print(f"æˆåŠŸå¤„ç†: {len(all_vehicle_ids)} ä¸ªè½¦è¾†")
    print(f"è½¦è¾†åˆ—è¡¨:")
    for vid in all_vehicle_ids:
        print(f"  - {vid}")
    print('='*60)

    return all_vehicle_ids


def main():
    """
    ä¸»å‡½æ•° - æ‰¹é‡é¢„å¤„ç†æ¨¡å¼
    """
    print("\n" + "="*60)
    print("è½¨è¿¹æ•°æ®é¢„å¤„ç†ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰")
    print("="*60)
    print(f"è¾“å…¥ç›®å½•: {CONFIG['input_dir']}")
    print(f"è¾“å‡ºç›®å½•: {CONFIG['output_dir']}")
    print(f"å¹¶è¡Œå¤„ç†: {'å¯ç”¨' if CONFIG['parallel'] else 'ç¦ç”¨'}")
    if CONFIG['parallel']:
        workers = CONFIG['n_workers'] or os.cpu_count()
        print(f"å·¥ä½œè¿›ç¨‹æ•°: {workers}")
    print("="*60)

    try:
        all_vehicle_ids = preprocess_all_trajectories(
            CONFIG['input_dir'],
            CONFIG['output_dir'],
            parallel=CONFIG['parallel'],
            n_workers=CONFIG['n_workers']
        )
        print(f"\nâœ… æ‰¹é‡é¢„å¤„ç†å®Œæˆï¼Œå…±ç”Ÿæˆ {len(all_vehicle_ids)} ä¸ªè½¦è¾†æ–‡ä»¶")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
