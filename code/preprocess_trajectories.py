"""
è½¨è¿¹æ•°æ®é¢„å¤„ç†è„šæœ¬

åŠŸèƒ½ï¼š
1. è¯»å–åŸå§‹è½¨è¿¹CSVæ–‡ä»¶ï¼ˆæ— è¡¨å¤´æ ¼å¼ï¼‰
2. æ·»åŠ æ ‡å‡†åˆ—å
3. è§£ædatetimeæ ¼å¼
4. æå–è½¦è¾†IDï¼ˆè‹±æ–‡æ ‡è¯†ï¼‰
5. ä½¿ç”¨ transbigdata è¿›è¡Œæ•°æ®æ¸…æ´—ï¼š
   - æ¸…ç†è¾¹ç•Œå¤–æ•°æ®ï¼ˆæ·±åœ³åŒºåŸŸï¼‰
   - æ¸…ç†å†—ä½™é‡å¤è®°å½•
   - æ¸…ç†æ¼‚ç§»å¼‚å¸¸ç‚¹ï¼ˆé€Ÿåº¦/è·ç¦»/è§’åº¦ï¼‰
6. æ”¯æŒå¹¶è¡Œå¤„ç†å¤šä¸ªæ–‡ä»¶
7. ä¿å­˜ä¸ºæ ‡å‡†CSVæ ¼å¼

ä½¿ç”¨æ–¹æ³•ï¼š
    åœ¨è„šæœ¬å†…éƒ¨ä¿®æ”¹CONFIGé…ç½®åç›´æ¥è¿è¡Œï¼š
    python preprocess_trajectories.py

é…ç½®è¯´æ˜ï¼š
    - mode: 'single' å¤„ç†å•ä¸ªæ–‡ä»¶, 'batch' æ‰¹é‡å¤„ç†
    - parallel: True/False æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†ï¼ˆä»…æ‰¹é‡æ¨¡å¼æœ‰æ•ˆï¼‰
    - n_workers: å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ˆNone=è‡ªåŠ¨æ£€æµ‹CPUæ ¸å¿ƒæ•°ï¼‰
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
import transbigdata as tbd
from concurrent.futures import ProcessPoolExecutor, as_completed
import os


# ==================== é…ç½®å‚æ•° ====================
CONFIG = {
    # å¤„ç†æ¨¡å¼ï¼š'single' å¤„ç†å•ä¸ªæ–‡ä»¶ï¼Œ'batch' æ‰¹é‡å¤„ç†ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶
    'mode': 'batch',

    # å•æ–‡ä»¶æ¨¡å¼ï¼šæŒ‡å®šè¾“å…¥æ–‡ä»¶è·¯å¾„
    'input_file': 'traj/Z8.csv',

    # æ‰¹é‡æ¨¡å¼ï¼šæŒ‡å®šè¾“å…¥ç›®å½•
    'input_dir': '../traj',

    # è¾“å‡ºç›®å½•
    'output_dir': '../traj',

    # å¹¶è¡Œå¤„ç†é…ç½®
    'parallel': True,           # æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
    'n_workers': 10           # å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ˆNone = è‡ªåŠ¨ä½¿ç”¨ CPU æ ¸å¿ƒæ•°ï¼‰
}
# =================================================


def extract_vehicle_id(raw_id):
    """
    ä»åŸå§‹è½¦ç‰Œæå–è‹±æ–‡è½¦è¾†ID

    Parameters
    ----------
    raw_id : str
        åŸå§‹è½¦ç‰Œå·ï¼Œå¦‚ "ç²¤B7J7Z8"

    Returns
    -------
    str
        è‹±æ–‡è½¦è¾†IDï¼Œå¦‚ "Z8"

    Examples
    --------
    >>> extract_vehicle_id("ç²¤B7J7Z8")
    'Z8'
    >>> extract_vehicle_id("ç²¤B2L90G")
    '0G'
    """
    # æå–æœ€åä¸¤ä½ä½œä¸ºè½¦è¾†ID
    return raw_id[-2:]


def preprocess_trajectory(input_path, output_dir='traj'):
    """
    é¢„å¤„ç†å•ä¸ªè½¨è¿¹æ–‡ä»¶

    Parameters
    ----------
    input_path : str or Path
        è¾“å…¥CSVæ–‡ä»¶è·¯å¾„
    output_dir : str
        è¾“å‡ºç›®å½•

    Returns
    -------
    tuple
        (vehicle_id, output_path, stats)
    """
    input_path = Path(input_path)

    print(f"\n{'='*60}")
    print(f"é¢„å¤„ç†è½¨è¿¹æ–‡ä»¶: {input_path.name}")
    print('='*60)

    # è¯»å–åŸå§‹CSVï¼ˆæ— è¡¨å¤´ï¼‰
    print("ğŸ“‚ è¯»å–åŸå§‹CSV...")
    df = pd.read_csv(input_path, header=None, names=[
        'datetime', 'vehicle_id', 'lng', 'lat',
        'speed', 'angle', 'operation_status'
    ])

    print(f"   åŸå§‹è®°å½•æ•°: {len(df):,}")

    # è§£ædatetime
    print("ğŸ• è§£ædatetimeæ ¼å¼...")
    df['datetime'] = pd.to_datetime(df['datetime'], format='%Y%m%d%H%M%S')
    df['datetime'] = df['datetime'].dt.tz_localize('Asia/Shanghai')  # æ ‡è®°ä¸ºæ·±åœ³/ä¸­å›½æ—¶åŒº

    # æå–è½¦è¾†ID
    raw_vehicle_id = df['vehicle_id'].iloc[0]
    vehicle_id = extract_vehicle_id(raw_vehicle_id)
    print(f"ğŸš— è½¦è¾†ID: {raw_vehicle_id} â†’ {vehicle_id}")

    # æ•°æ®éªŒè¯
    print("âœ… æ•°æ®éªŒè¯...")

    # ä½¿ç”¨ transbigdata æ¸…ç†è¾¹ç•Œå¤–æ•°æ®ï¼ˆæ·±åœ³åŒºåŸŸï¼‰
    records_before = len(df)
    df = tbd.clean_outofbounds(
        df,
        bounds=[113, 22, 115, 23],  # [lng_min, lat_min, lng_max, lat_max]
        col=['lng', 'lat']
    )
    removed_coords = records_before - len(df)
    if removed_coords > 0:
        print(f"   âš ï¸  [transbigdata] ç§»é™¤ {removed_coords} æ¡è¾¹ç•Œå¤–è®°å½•")

    # æ£€æŸ¥è§’åº¦èŒƒå›´
    invalid_angle = (df['angle'] < 0) | (df['angle'] > 359)
    if invalid_angle.sum() > 0:
        print(f"   âš ï¸  å‘ç° {invalid_angle.sum()} æ¡è§’åº¦å¼‚å¸¸è®°å½•")
        df = df[~invalid_angle]

    # ä½¿ç”¨ transbigdata æ¸…ç†é‡å¤è®°å½•
    records_before = len(df)
    df = tbd.traj_clean_redundant(
        df,
        col=['vehicle_id', 'datetime', 'lng', 'lat']
    )
    removed_duplicates = records_before - len(df)
    if removed_duplicates > 0:
        print(f"   âš ï¸  [transbigdata] ç§»é™¤ {removed_duplicates} æ¡å†—ä½™è®°å½•")

    # ä½¿ç”¨ transbigdata æ¸…ç†æ¼‚ç§»å¼‚å¸¸ç‚¹ï¼ˆç»¼åˆé€Ÿåº¦ã€è·ç¦»ã€è§’åº¦ï¼‰
    records_before = len(df)
    df = tbd.traj_clean_drift(
        df,
        col=['vehicle_id', 'datetime', 'lng', 'lat'],
        speedlimit=100,      # é€Ÿåº¦ä¸Šé™ 100 km/h
        dislimit=1000,      # è·ç¦»ä¸Šé™ 1000 ç±³
        anglelimit=30       # è§’åº¦å˜åŒ–ä¸Šé™ 30 åº¦
    )
    removed_drift = records_before - len(df)
    if removed_drift > 0:
        print(f"   âš ï¸  [transbigdata] ç§»é™¤ {removed_drift} æ¡æ¼‚ç§»å¼‚å¸¸ç‚¹")

    # ç»Ÿè®¡ä¿¡æ¯
    stats = {
        'vehicle_id': vehicle_id,
        'raw_vehicle_id': raw_vehicle_id,
        'total_records': len(df),
        'time_range': (df['datetime'].min(), df['datetime'].max()),
        'duration_hours': (df['datetime'].max() - df['datetime'].min()).total_seconds() / 3600,
        'avg_speed': df['speed'].mean(),
        'coord_bounds': {
            'lng_min': df['lng'].min(),
            'lng_max': df['lng'].max(),
            'lat_min': df['lat'].min(),
            'lat_max': df['lat'].max()
        }
    }

    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   æœ‰æ•ˆè®°å½•æ•°: {stats['total_records']:,}")
    print(f"   æ—¶é—´èŒƒå›´: {stats['time_range'][0]} è‡³ {stats['time_range'][1]}")
    print(f"   æŒç»­æ—¶é—´: {stats['duration_hours']:.2f} å°æ—¶")
    print(f"   å¹³å‡é€Ÿåº¦: {stats['avg_speed']:.1f} km/h")
    print(f"   ç»åº¦èŒƒå›´: {stats['coord_bounds']['lng_min']:.4f} ~ {stats['coord_bounds']['lng_max']:.4f}")
    print(f"   çº¬åº¦èŒƒå›´: {stats['coord_bounds']['lat_min']:.4f} ~ {stats['coord_bounds']['lat_max']:.4f}")

    # ä¿å­˜å¤„ç†åçš„CSV
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    output_filename = f"{vehicle_id}_processed.csv"
    output_path = output_dir / output_filename

    df.to_csv(output_path, index=False)
    file_size_mb = output_path.stat().st_size / (1024 * 1024)

    print(f"\nğŸ’¾ ä¿å­˜åˆ°: {output_path}")
    print(f"   æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
    print('='*60)

    return vehicle_id, output_path, stats


def _process_single_file(args):
    """
    å•ä¸ªæ–‡ä»¶å¤„ç†çš„åŒ…è£…å‡½æ•°ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰

    Parameters
    ----------
    args : tuple
        (csv_file, output_dir)

    Returns
    -------
    tuple or None
        æˆåŠŸæ—¶è¿”å› (vehicle_id, stats)ï¼Œå¤±è´¥æ—¶è¿”å› None
    """
    csv_file, output_dir = args
    try:
        vehicle_id, output_path, stats = preprocess_trajectory(csv_file, output_dir)
        return (vehicle_id, stats)
    except Exception as e:
        print(f"\nâŒ å¤„ç† {csv_file.name} å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def preprocess_all_trajectories(input_dir='traj', output_dir='traj', parallel=False, n_workers=None):
    """
    æ‰¹é‡é¢„å¤„ç†æ‰€æœ‰è½¨è¿¹æ–‡ä»¶

    Parameters
    ----------
    input_dir : str
        è¾“å…¥ç›®å½•
    output_dir : str
        è¾“å‡ºç›®å½•
    parallel : bool
        æ˜¯å¦å¯ç”¨å¹¶è¡Œå¤„ç†
    n_workers : int or None
        å¹¶è¡Œå·¥ä½œè¿›ç¨‹æ•°ï¼ˆNone = è‡ªåŠ¨ä½¿ç”¨ CPU æ ¸å¿ƒæ•°ï¼‰

    Returns
    -------
    dict
        æ‰€æœ‰è½¦è¾†çš„ç»Ÿè®¡ä¿¡æ¯
    """
    input_dir = Path(input_dir)

    # æŸ¥æ‰¾æ‰€æœ‰åŸå§‹CSVæ–‡ä»¶ï¼ˆæ’é™¤å·²å¤„ç†çš„ï¼‰
    csv_files = list(input_dir.glob('*.csv'))
    csv_files = [f for f in csv_files if '_processed' not in f.name]

    if not csv_files:
        print("æœªæ‰¾åˆ°å¾…å¤„ç†çš„CSVæ–‡ä»¶")
        return {}

    print(f"\n{'='*60}")
    print(f"æ‰¹é‡é¢„å¤„ç†è½¨è¿¹æ•°æ®")
    print('='*60)
    print(f"å‘ç° {len(csv_files)} ä¸ªå¾…å¤„ç†æ–‡ä»¶:")
    for f in csv_files:
        print(f"  - {f.name}")

    if parallel and len(csv_files) > 1:
        # å¹¶è¡Œå¤„ç†æ¨¡å¼
        if n_workers is None:
            n_workers = os.cpu_count()
        print(f"\nğŸš€ å¯ç”¨å¹¶è¡Œå¤„ç†æ¨¡å¼ï¼ˆ{n_workers} ä¸ªå·¥ä½œè¿›ç¨‹ï¼‰")

        all_stats = {}
        with ProcessPoolExecutor(max_workers=n_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(_process_single_file, (csv_file, output_dir)): csv_file
                for csv_file in csv_files
            }

            # æ”¶é›†ç»“æœ
            completed = 0
            for future in as_completed(future_to_file):
                completed += 1
                result = future.result()
                if result is not None:
                    vehicle_id, stats = result
                    all_stats[vehicle_id] = stats
                print(f"   è¿›åº¦: {completed}/{len(csv_files)}")
    else:
        # ä¸²è¡Œå¤„ç†æ¨¡å¼
        if parallel:
            print(f"\nâš ï¸  æ–‡ä»¶æ•°é‡å°‘äº2ä¸ªï¼Œä½¿ç”¨ä¸²è¡Œå¤„ç†")
        else:
            print(f"\nğŸ“ ä½¿ç”¨ä¸²è¡Œå¤„ç†æ¨¡å¼")

        all_stats = {}
        for csv_file in csv_files:
            try:
                vehicle_id, output_path, stats = preprocess_trajectory(
                    csv_file, output_dir
                )
                all_stats[vehicle_id] = stats
            except Exception as e:
                print(f"\nâŒ å¤„ç† {csv_file.name} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                continue

    # æ±‡æ€»æŠ¥å‘Š
    print(f"\n{'='*60}")
    print("é¢„å¤„ç†æ±‡æ€»")
    print('='*60)
    print(f"æˆåŠŸå¤„ç†: {len(all_stats)} ä¸ªè½¨è¿¹æ–‡ä»¶")

    total_records = sum(s['total_records'] for s in all_stats.values())
    total_duration = sum(s['duration_hours'] for s in all_stats.values())

    print(f"æ€»è®°å½•æ•°: {total_records:,}")
    print(f"æ€»æ—¶é•¿: {total_duration:.2f} å°æ—¶")
    print()

    for vid, stats in all_stats.items():
        print(f"  {vid}: {stats['total_records']:,} æ¡è®°å½•, "
              f"{stats['duration_hours']:.2f}h, "
              f"å¹³å‡é€Ÿåº¦ {stats['avg_speed']:.1f} km/h")

    print('='*60)

    return all_stats


def main():
    """
    ä¸»å‡½æ•°

    æ ¹æ®CONFIGé…ç½®è¿è¡Œé¢„å¤„ç†ä»»åŠ¡
    """
    print("\n" + "="*60)
    print("è½¨è¿¹æ•°æ®é¢„å¤„ç†")
    print("="*60)
    print(f"å¤„ç†æ¨¡å¼: {CONFIG['mode']}")

    if CONFIG['mode'] == 'single':
        print(f"è¾“å…¥æ–‡ä»¶: {CONFIG['input_file']}")
    else:
        print(f"è¾“å…¥ç›®å½•: {CONFIG['input_dir']}")

    print(f"è¾“å‡ºç›®å½•: {CONFIG['output_dir']}")
    if CONFIG['mode'] == 'batch':
        print(f"å¹¶è¡Œå¤„ç†: {'å¯ç”¨' if CONFIG['parallel'] else 'ç¦ç”¨'}")
        if CONFIG['parallel']:
            workers = CONFIG['n_workers'] or os.cpu_count()
            print(f"å·¥ä½œè¿›ç¨‹æ•°: {workers}")
    print("="*60)

    try:
        if CONFIG['mode'] == 'single':
            # å¤„ç†å•ä¸ªæ–‡ä»¶
            vehicle_id, output_path, stats = preprocess_trajectory(
                CONFIG['input_file'],
                CONFIG['output_dir']
            )
            print(f"\nâœ… é¢„å¤„ç†å®Œæˆ: {output_path}")
        elif CONFIG['mode'] == 'batch':
            # æ‰¹é‡å¤„ç†
            all_stats = preprocess_all_trajectories(
                CONFIG['input_dir'],
                CONFIG['output_dir'],
                parallel=CONFIG['parallel'],
                n_workers=CONFIG['n_workers']
            )
            print(f"\nâœ… æ‰¹é‡é¢„å¤„ç†å®Œæˆ")
        else:
            raise ValueError(f"æ— æ•ˆçš„å¤„ç†æ¨¡å¼: {CONFIG['mode']}ï¼Œè¯·ä½¿ç”¨ 'single' æˆ– 'batch'")

    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1

    return 0


if __name__ == "__main__":
    exit(main())
