"""
æ‰¹é‡å¤„ç†è½¨è¿¹æ•°æ® - å•GPUä¸²è¡Œè®¡ç®—

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨å‘ç°è½¨è¿¹ç›®å½•ä¸­çš„é¢„å¤„ç†è½¨è¿¹æ–‡ä»¶
2. è‡ªåŠ¨è¯†åˆ«æºæœˆä»½ï¼Œå…‹éš†è½¨è¿¹åˆ°å…¨å¹´12ä¸ªæœˆ
3. ä¸ºæ¯ä¸ªæœˆä»½è·å–å¯¹åº”çš„æ°”è±¡æ•°æ®
4. è®¡ç®—å…¨å¹´12ä¸ªæœˆçš„å…‰ä¼å‘ç”µé‡
5. ä¿å­˜åˆå¹¶çš„å…¨å¹´ç»“æœåˆ°å•ä¸ªæ–‡ä»¶
6. ç”Ÿæˆæ‰¹å¤„ç†æ±‡æ€»æŠ¥å‘Š

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # ä½¿ç”¨å†…éƒ¨CONFIGé…ç½®
    python batch_process_trajectories.py

    # ä½¿ç”¨å¤–éƒ¨config.yamlï¼ˆå¯é€‰ï¼‰
    python batch_process_trajectories.py --config config.yaml

    # æŒ‡å®šä½¿ç”¨GPU 0
    python batch_process_trajectories.py --gpu 0

    # ç»„åˆä½¿ç”¨
    python batch_process_trajectories.py --config config.yaml --gpu 1
"""

import os
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import trimesh
import yaml
import argparse
from datetime import datetime
import time
import gc  # åƒåœ¾å›æ”¶

print("\nğŸ“¦ æ­£åœ¨å¯¼å…¥æ¨¡å—...", flush=True)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
print("   - å¯¼å…¥ prepare_building_mesh_from_footprint...", flush=True)
from prepare_building_mesh_from_footprint import prepare_building_mesh_from_footprint

print("   - å¯¼å…¥ fetch_irradiance_data...", flush=True)
from fetch_irradiance_data import fetch_and_cache_irradiance_data, convert_to_pvlib_format

print("   - å¯¼å…¥ pv_calculator_gpu...", flush=True)
from pv_calculator_gpu import GPUAcceleratedSolarPVCalculator

print("   âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥å®Œæˆï¼\n", flush=True)


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================
def detect_source_month(df, datetime_column='datetime'):
    """
    è‡ªåŠ¨æ£€æµ‹è½¨è¿¹æ•°æ®çš„æºæœˆä»½

    Parameters
    ----------
    df : pandas.DataFrame
        è½¨è¿¹æ•°æ®
    datetime_column : str
        æ—¥æœŸæ—¶é—´åˆ—å

    Returns
    -------
    int
        æºæœˆä»½ (1-12)
    """
    month_counts = df[datetime_column].dt.month.value_counts()
    source_month = month_counts.idxmax()
    return int(source_month)


def clone_trajectory_to_month(df, target_month, datetime_column='datetime'):
    """
    å°†è½¨è¿¹æ—¶é—´æˆ³å…‹éš†åˆ°ç›®æ ‡æœˆä»½

    Parameters
    ----------
    df : pandas.DataFrame
        åŸå§‹è½¨è¿¹æ•°æ®
    target_month : int
        ç›®æ ‡æœˆä»½ (1-12)
    datetime_column : str
        æ—¥æœŸæ—¶é—´åˆ—å

    Returns
    -------
    pandas.DataFrame
        æ—¶é—´æˆ³å·²è½¬æ¢çš„è½¨è¿¹æ•°æ®ï¼ˆè¿‡æ»¤æ‰æ— æ•ˆæ—¥æœŸï¼‰
    """
    original_dt = df[datetime_column]

    # ä¿å­˜åŸå§‹æ—¶åŒºä¿¡æ¯
    original_tz = original_dt.dt.tz

    # ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ„å»ºæ–°æ—¥æœŸ
    try:
        new_dates = pd.to_datetime({
            'year': original_dt.dt.year,
            'month': target_month,
            'day': original_dt.dt.day,
            'hour': original_dt.dt.hour,
            'minute': original_dt.dt.minute,
            'second': original_dt.dt.second,
        }, errors='coerce')
    except Exception:
        # å¦‚æœå‘é‡åŒ–å¤±è´¥ï¼Œå›é€€åˆ°applyæ–¹æ³•
        def replace_month(dt):
            try:
                return dt.replace(month=target_month)
            except ValueError:
                return pd.NaT
        new_dates = original_dt.apply(replace_month)

    # æ¢å¤æ—¶åŒºä¿¡æ¯
    if original_tz is not None:
        new_dates = new_dates.dt.tz_localize(original_tz)

    # æ‰¾å‡ºæœ‰æ•ˆæ—¥æœŸçš„è¡Œ
    valid_mask = new_dates.notna()

    # å¤åˆ¶æœ‰æ•ˆè¡Œå¹¶æ›´æ–°æ—¶é—´æˆ³
    df_cloned = df[valid_mask].copy()
    df_cloned[datetime_column] = new_dates[valid_mask]

    return df_cloned, (~valid_mask).sum()


# ============================================================================
# é…ç½®å‚æ•° - åœ¨æ­¤ä¿®æ”¹æ‚¨çš„è®¾ç½®
# ============================================================================
CONFIG = {
    'location': {
        'name': 'æ·±åœ³å¸‚',
        'lat': 22.543099,
        'lon': 114.057868,
    },
    'data_sources': {
        'footprint_path': 'data/shenzhen_buildings.geojson',
        'trajectory_dir': '../../../../data2/hcr/evipv/shenzhendata/taxi/taxi/processed',  # è½¨è¿¹æ–‡ä»¶ç›®å½•
    },
    'pv_system': {
        'panel_area': 2.2,          # å…‰ä¼æ¿é¢ç§¯(mÂ²)
        'panel_efficiency': 0.20,   # æ•ˆç‡ 20%
        'tilt': 0,                  # å€¾è§’(åº¦)
        'vehicle_height': 1.5,      # è½¦é¡¶é«˜åº¦(m)
    },
    'computation': {
        'time_resolution_minutes': 1,  # æ—¶é—´åˆ†è¾¨ç‡
        'use_gpu': True,               # å¯ç”¨GPU
        'gpu_id': 0,                   # GPUç¼–å· (0, 1, 2...), None=è‡ªåŠ¨é€‰æ‹©
        'batch_size': 10000,             # æ‰¹å¤„ç†å¤§å°
        'mesh_grid_size': None,        # meshç½‘æ ¼å¤§å°(m), None=ä¸ç»†åˆ†
        'clone_to_all_months': True,   # æ˜¯å¦å…‹éš†åˆ°å…¨å¹´12ä¸ªæœˆ
        'max_vehicles': None,          # æœ€å¤§å¤„ç†è½¦è¾†æ•°, None=ä¸é™åˆ¶
    },
    'output': {
        'mesh_path': 'data/shenzhen_building_mesh.ply',
        'output_dir': 'output',
    },
}


def load_config(config_path='config.yaml'):
    """
    åŠ è½½å¤–éƒ¨é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰

    å¦‚æœæä¾›config.yamlï¼Œå°†è¦†ç›–å†…éƒ¨CONFIG
    å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨å†…éƒ¨CONFIG
    """
    if Path(config_path).exists():
        print(f"ğŸ“„ åŠ è½½å¤–éƒ¨é…ç½®æ–‡ä»¶: {config_path}")
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    else:
        return None


def find_processed_trajectories(traj_dir='traj'):
    """
    æŸ¥æ‰¾æ‰€æœ‰é¢„å¤„ç†åçš„è½¨è¿¹æ–‡ä»¶

    Parameters
    ----------
    traj_dir : str
        è½¨è¿¹æ–‡ä»¶ç›®å½•

    Returns
    -------
    list
        è½¨è¿¹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    traj_dir = Path(traj_dir)
    traj_files = list(traj_dir.glob('*_processed.csv'))

    return sorted(traj_files)


def calculate_stats(result_df):
    """
    è®¡ç®—è½¨è¿¹çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ”¯æŒå…¨å¹´æ•°æ®ï¼‰

    Parameters
    ----------
    result_df : pandas.DataFrame
        è®¡ç®—ç»“æœ

    Returns
    -------
    dict
        ç»Ÿè®¡ä¿¡æ¯
    """
    stats = {
        'total_records': len(result_df),
        'total_energy_kwh': result_df['energy_kwh'].sum(),
        'avg_power_w': result_df['ac_power'].mean(),
        'max_power_w': result_df['ac_power'].max(),
        'shaded_ratio': result_df['is_shaded'].mean(),
        'avg_cell_temp': result_df['cell_temp'].mean(),
        'time_range': (result_df['datetime'].min(), result_df['datetime'].max()),
    }

    # æŒ‰æœˆç»Ÿè®¡
    if 'month' in result_df.columns:
        monthly_energy = result_df.groupby('month')['energy_kwh'].sum().to_dict()
        stats['monthly_energy_kwh'] = monthly_energy

    return stats


def save_batch_summary(all_stats, output_path):
    """
    ä¿å­˜æ‰¹å¤„ç†æ±‡æ€»æŠ¥å‘Š

    Parameters
    ----------
    all_stats : dict
        æ‰€æœ‰è½¦è¾†çš„ç»Ÿè®¡ä¿¡æ¯
    output_path : str or Path
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("="*60 + "\n")
        f.write("Batch Processing Summary - All Vehicles (Full Year)\n")
        f.write("="*60 + "\n\n")
        f.write(f"Processing Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Total Vehicles: {len(all_stats)}\n\n")

        total_energy = sum(s['stats']['total_energy_kwh'] for s in all_stats.values())
        total_time = sum(s['elapsed_time'] for s in all_stats.values())

        f.write("Overall Summary:\n")
        f.write(f"  Total Energy (All Vehicles, Full Year): {total_energy:.2f} kWh\n")
        f.write(f"  Total Calculation Time: {total_time:.1f} seconds ({total_time/60:.1f} min)\n\n")

        # æŒ‰æœˆæ±‡æ€»
        monthly_totals = {}
        for vehicle_id, data in all_stats.items():
            if 'monthly_energy_kwh' in data['stats']:
                for month, energy in data['stats']['monthly_energy_kwh'].items():
                    monthly_totals[month] = monthly_totals.get(month, 0) + energy

        if monthly_totals:
            f.write("Monthly Energy Summary (All Vehicles):\n")
            for month in sorted(monthly_totals.keys()):
                f.write(f"  Month {month:02d}: {monthly_totals[month]:.2f} kWh\n")
            f.write("\n")

        f.write("Per-Vehicle Statistics:\n")
        f.write("-"*60 + "\n")

        for vehicle_id, data in all_stats.items():
            stats = data['stats']
            f.write(f"\n{vehicle_id}:\n")
            f.write(f"  Records: {stats['total_records']:,}\n")
            f.write(f"  Total Energy (Full Year): {stats['total_energy_kwh']:.2f} kWh\n")
            f.write(f"  Avg Power: {stats['avg_power_w']:.2f} W\n")
            f.write(f"  Peak Power: {stats['max_power_w']:.2f} W\n")
            f.write(f"  Shaded Ratio: {stats['shaded_ratio']*100:.1f}%\n")
            f.write(f"  Calculation Time: {data['elapsed_time']:.1f}s\n")

            # æ˜¾ç¤ºæ¯æœˆå‘ç”µé‡
            if 'monthly_energy_kwh' in stats:
                f.write(f"  Monthly Breakdown:\n")
                for month in sorted(stats['monthly_energy_kwh'].keys()):
                    f.write(f"    Month {month:02d}: {stats['monthly_energy_kwh'][month]:.2f} kWh\n")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡å¤„ç†è½¨è¿¹æ•°æ®è®¡ç®—å…‰ä¼å‘ç”µé‡ï¼ˆå•GPUä¸²è¡Œï¼Œå…¨å¹´ç‰ˆæœ¬ï¼‰'
    )
    parser.add_argument(
        '--config', '-c',
        default=None,
        help='å¤–éƒ¨é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨è„šæœ¬å†…éƒ¨CONFIGï¼‰'
    )
    parser.add_argument(
        '--gpu', '-g',
        type=int,
        default=None,
        help='æŒ‡å®šGPUç¼–å· (0, 1, 2...), ä¸æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®'
    )

    args = parser.parse_args()

    print("\n" + "="*80)
    print(" "*15 + "ğŸš€ Batch Vehicle PV Generation Calculation (GPU)")
    print(" "*20 + "Full Year Mode - 12 Months")
    print("="*80)
    print(f"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # åŠ è½½é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨å¤–éƒ¨é…ç½®ï¼Œå¦åˆ™ä½¿ç”¨å†…éƒ¨CONFIG
    if args.config:
        external_config = load_config(args.config)
        if external_config:
            config = external_config
        else:
            print(f"âš ï¸  å¤–éƒ¨é…ç½®æ–‡ä»¶ {args.config} ä¸å­˜åœ¨ï¼Œä½¿ç”¨å†…éƒ¨CONFIG")
            config = CONFIG
    else:
        print("ğŸ“‹ ä½¿ç”¨è„šæœ¬å†…éƒ¨CONFIGé…ç½®")
        config = CONFIG

    # GPUè®¾ç½®ï¼šå‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆäºé…ç½®æ–‡ä»¶
    gpu_id = args.gpu if args.gpu is not None else config['computation'].get('gpu_id', 0)

    if config['computation']['use_gpu'] and gpu_id is not None:
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
        print(f"ğŸ® GPUè®¾ç½®: ä½¿ç”¨GPU {gpu_id}")
        print(f"   ç¯å¢ƒå˜é‡: CUDA_VISIBLE_DEVICES={gpu_id}")
    elif config['computation']['use_gpu']:
        print(f"ğŸ® GPUè®¾ç½®: ä½¿ç”¨é»˜è®¤GPUï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰")
    else:
        print(f"ğŸ’» GPUè®¾ç½®: GPUå·²ç¦ç”¨ï¼Œä½¿ç”¨CPU")

    # å…¨å¹´æ¨¡å¼æç¤º
    clone_to_all_months = config['computation'].get('clone_to_all_months', True)
    if clone_to_all_months:
        print(f"ğŸ“… å…¨å¹´æ¨¡å¼: å¯ç”¨ (å°†å…‹éš†è½¨è¿¹åˆ°12ä¸ªæœˆ)")
    else:
        print(f"ğŸ“… å…¨å¹´æ¨¡å¼: ç¦ç”¨ (ä»…è®¡ç®—åŸå§‹æœˆä»½)")

    # GPUå¯ç”¨æ€§æ£€æŸ¥
    if config['computation']['use_gpu']:
        try:
            import torch
            print(f"\nğŸ” GPUå¯ç”¨æ€§æ£€æŸ¥:")
            print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
            print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
                print(f"   å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
                print(f"   å½“å‰GPU: {torch.cuda.current_device()}")
                print(f"   GPUåç§°: {torch.cuda.get_device_name(0)}")
                print(f"   GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

                # æµ‹è¯•GPUæ˜¯å¦çœŸçš„å¯ç”¨
                print(f"\nğŸ§ª GPUæ€§èƒ½æµ‹è¯•...")
                test_start = time.time()
                test_tensor = torch.randn(1000, 1000).cuda()
                test_result = torch.matmul(test_tensor, test_tensor)
                torch.cuda.synchronize()
                test_time = time.time() - test_start
                print(f"   âœ… GPUæµ‹è¯•æˆåŠŸ! è€—æ—¶: {test_time:.3f}s")
            else:
                print(f"   âš ï¸  è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®¡ç®—ï¼ˆä¼šå¾ˆæ…¢ï¼‰")
        except Exception as e:
            print(f"   âŒ GPUæ£€æŸ¥å¤±è´¥: {e}")

    print("="*80)

    # è®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
    traj_dir = Path(config['data_sources']['trajectory_dir'])
    output_dir = Path(config['output']['output_dir'])
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"\nğŸ“ è½¨è¿¹ç›®å½•: {traj_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("="*80)

    # å‡†å¤‡å»ºç­‘mesh
    print("\n" + "="*80)
    print("Preparing Building Mesh")
    print("="*80)

    mesh_start_time = time.time()
    mesh_path = Path(config['output']['mesh_path'])

    if mesh_path.exists():
        print(f"â±ï¸  [{datetime.now().strftime('%H:%M:%S')}] Loading existing mesh: {mesh_path}")
        building_mesh = trimesh.load(mesh_path)
        print(f"   Vertices: {len(building_mesh.vertices):,}")
        print(f"   Faces: {len(building_mesh.faces):,}")
        print(f"   âœ… MeshåŠ è½½å®Œæˆï¼Œè€—æ—¶: {time.time() - mesh_start_time:.2f}s")
    else:
        print(f"â±ï¸  [{datetime.now().strftime('%H:%M:%S')}] Converting footprint to mesh...")
        print(f"   âš ï¸  è¿™æ˜¯é¦–æ¬¡è¿è¡Œï¼Œç”Ÿæˆmeshå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆæ•°åˆ†é’Ÿï¼‰...")
        building_mesh = prepare_building_mesh_from_footprint(
            footprint_path=config['data_sources']['footprint_path'],
            output_mesh_path=str(mesh_path),
            grid_size=config['computation']['mesh_grid_size']
        )
        print(f"   âœ… Meshç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {time.time() - mesh_start_time:.2f}s")

    # åˆå§‹åŒ–GPUè®¡ç®—å™¨
    print("\n" + "="*80, flush=True)
    print("Initialize GPU Calculator", flush=True)
    print("="*80, flush=True)

    calc_init_start = time.time()
    print(f"â±ï¸  [{datetime.now().strftime('%H:%M:%S')}] æ­£åœ¨åˆå§‹åŒ–GPUè®¡ç®—å™¨...", flush=True)
    print(f"   è¿™ä¸€æ­¥å¯èƒ½éœ€è¦10-30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…...", flush=True)

    calculator = GPUAcceleratedSolarPVCalculator(
        lon_center=config['location']['lon'],
        lat_center=config['location']['lat'],
        building_mesh=building_mesh,
        panel_area=config['pv_system']['panel_area'],
        panel_efficiency=config['pv_system']['panel_efficiency'],
        time_resolution_minutes=config['computation']['time_resolution_minutes'],
        use_gpu=config['computation']['use_gpu'],
        batch_size=config['computation']['batch_size']
    )

    print(f"   âœ… GPUè®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {time.time() - calc_init_start:.2f}s", flush=True)

    # æŸ¥æ‰¾è½¨è¿¹æ–‡ä»¶
    print("\n" + "="*80)
    print("Step 1: Discover Trajectory Files")
    print("="*80)

    traj_files = find_processed_trajectories(traj_dir)

    if not traj_files:
        print(f"âš ï¸  No processed trajectory files found in {traj_dir}/")
        print(f"   è¯·ç¡®ä¿è½¨è¿¹æ–‡ä»¶ä»¥ '_processed.csv' ç»“å°¾")
        return 1

    # é™åˆ¶æœ€å¤§è½¦è¾†æ•°
    max_vehicles = config['computation'].get('max_vehicles', None)
    if max_vehicles and len(traj_files) > max_vehicles:
        print(f"âš ï¸  Found {len(traj_files)} files, limiting to first {max_vehicles}")
        traj_files = traj_files[:max_vehicles]

    print(f"âœ… Found {len(traj_files)} processed trajectory files:")
    for f in traj_files:
        vehicle_id = f.stem.replace('_processed', '')
        print(f"  - {f.name} â†’ Vehicle ID: {vehicle_id}")

    # æ‰¹é‡å¤„ç†è½¨è¿¹
    print("\n" + "="*80)
    print("Step 2: Process Trajectories (Full Year)")
    print("="*80)

    all_stats = {}

    for idx, traj_file in enumerate(traj_files, 1):
        vehicle_id = traj_file.stem.replace('_processed', '')

        print(f"\n{'='*80}")
        print(f"Processing Vehicle {idx}/{len(traj_files)}: {vehicle_id}")
        print('='*80)

        try:
            # è¯»å–è½¨è¿¹
            print(f"\nğŸ“‚ Loading trajectory: {traj_file.name}", flush=True)

            trajectory_df = pd.read_csv(traj_file)
            trajectory_df['datetime'] = pd.to_datetime(trajectory_df['datetime'])

            # ç¡®ä¿æ—¶é—´æˆ³æœ‰æ—¶åŒºä¿¡æ¯ï¼ˆä¸æ°”è±¡æ•°æ®åŒ¹é…ï¼‰
            if trajectory_df['datetime'].dt.tz is None:
                trajectory_df['datetime'] = trajectory_df['datetime'].dt.tz_localize('Asia/Shanghai')

            print(f"   Records: {len(trajectory_df):,}", flush=True)

            # æ£€æµ‹æºæœˆä»½
            source_month = detect_source_month(trajectory_df)
            print(f"   Source Month: {source_month}", flush=True)

            # ç¡®å®šè¦å¤„ç†çš„æœˆä»½
            if clone_to_all_months:
                months_to_process = list(range(1, 13))
                print(f"   Months to Process: 1-12 (Full Year)", flush=True)
            else:
                months_to_process = [source_month]
                print(f"   Months to Process: {source_month} only", flush=True)

            # è·å–å¹´ä»½ç”¨äºæ°”è±¡æ•°æ®
            base_year = trajectory_df['datetime'].dt.year.mode()[0]

            # å­˜å‚¨æ‰€æœ‰æœˆä»½çš„ç»“æœ
            all_monthly_results = []
            vehicle_start_time = time.time()

            for target_month in months_to_process:
                print(f"\nğŸ“… Processing Month {target_month:02d}/12...", flush=True)

                # å…‹éš†è½¨è¿¹åˆ°ç›®æ ‡æœˆä»½
                if target_month == source_month:
                    month_traj_df = trajectory_df.copy()
                    dropped_rows = 0
                else:
                    month_traj_df, dropped_rows = clone_trajectory_to_month(
                        trajectory_df, target_month
                    )

                if dropped_rows > 0:
                    print(f"   âš ï¸  Dropped {dropped_rows} rows (invalid dates)", flush=True)

                if len(month_traj_df) == 0:
                    print(f"   âš ï¸  No valid records for month {target_month}, skipping", flush=True)
                    continue

                # æ¨æ–­æ—¥æœŸèŒƒå›´
                start_date = month_traj_df['datetime'].min().strftime('%Y-%m-%d')
                end_date = month_traj_df['datetime'].max().strftime('%Y-%m-%d')

                # è·å–æ°”è±¡æ•°æ®
                print(f"   â˜€ï¸  Fetching irradiance data: {start_date} to {end_date}", flush=True)

                irrad_start = time.time()
                irradiance_data = fetch_and_cache_irradiance_data(
                    lat=config['location']['lat'],
                    lon=config['location']['lon'],
                    start_date=start_date,
                    end_date=end_date,
                    granularity='1min' if config['computation']['time_resolution_minutes'] == 1 else '1hour',
                    save_csv=False,
                    output_dir='irradiance_data'
                )
                weather_data = convert_to_pvlib_format(irradiance_data)
                print(f"   âœ… Weather data ready ({time.time() - irrad_start:.1f}s)", flush=True)

                # GPUè®¡ç®—
                print(f"   âš¡ Calculating PV generation...", flush=True)
                calc_start = time.time()

                result_df = calculator.process_trajectory(
                    month_traj_df,
                    weather_data=weather_data
                )

                # æ·»åŠ æœˆä»½åˆ—
                result_df['month'] = target_month

                all_monthly_results.append(result_df)

                month_energy = result_df['energy_kwh'].sum()
                print(f"   âœ… Month {target_month:02d}: {month_energy:.2f} kWh ({time.time() - calc_start:.1f}s)", flush=True)

                # æ¸…ç†ä¸­é—´å˜é‡
                del month_traj_df, irradiance_data, weather_data, result_df
                gc.collect()

            # åˆå¹¶æ‰€æœ‰æœˆä»½ç»“æœ
            if all_monthly_results:
                combined_result = pd.concat(all_monthly_results, ignore_index=True)

                elapsed_time = time.time() - vehicle_start_time

                # ä¿å­˜ç»“æœ
                print(f"\nğŸ’¾ Saving Results...", flush=True)
                result_csv = output_dir / f"{vehicle_id}_pv_generation.csv"
                combined_result.to_csv(result_csv, index=False)
                file_size_mb = result_csv.stat().st_size / (1024 * 1024)
                print(f"   âœ… Saved: {result_csv}", flush=True)
                print(f"      Size: {file_size_mb:.2f} MB, Records: {len(combined_result):,}", flush=True)

                # æ”¶é›†ç»Ÿè®¡
                stats = calculate_stats(combined_result)
                all_stats[vehicle_id] = {
                    'stats': stats,
                    'elapsed_time': elapsed_time
                }

                print(f"\nğŸ“Š Vehicle Summary:", flush=True)
                print(f"   Total Energy (Full Year): {stats['total_energy_kwh']:.2f} kWh", flush=True)
                print(f"   Avg Power: {stats['avg_power_w']:.2f} W", flush=True)
                print(f"   Peak Power: {stats['max_power_w']:.2f} W", flush=True)
                print(f"   Calculation Time: {elapsed_time:.1f}s", flush=True)

                # æ¸…ç†
                del combined_result, all_monthly_results
            else:
                print(f"\nâš ï¸  No results generated for {vehicle_id}", flush=True)

            # æ¸…ç†å†…å­˜
            del trajectory_df
            gc.collect()

            if config['computation']['use_gpu']:
                try:
                    import torch
                    torch.cuda.empty_cache()
                except:
                    pass

        except Exception as e:
            print(f"\nâŒ Error processing {vehicle_id}: {e}", flush=True)
            import traceback
            traceback.print_exc()

            # æ¸…ç†å†…å­˜
            gc.collect()
            if config['computation']['use_gpu']:
                try:
                    import torch
                    torch.cuda.empty_cache()
                except:
                    pass

            continue

    # ä¿å­˜æ‰¹å¤„ç†æ±‡æ€»
    print("\n" + "="*80)
    print("Step 3: Generate Summary")
    print("="*80)

    if all_stats:
        batch_summary_path = output_dir / "batch_summary.txt"
        save_batch_summary(all_stats, batch_summary_path)
        print(f"âœ… Batch Summary: {batch_summary_path}")

        print(f"\nğŸ“Š Processing Summary:")
        print(f"   Successfully Processed: {len(all_stats)} vehicles")
        total_energy = sum(s['stats']['total_energy_kwh'] for s in all_stats.values())
        total_time = sum(s['elapsed_time'] for s in all_stats.values())
        print(f"   Total Energy (All Vehicles, Full Year): {total_energy:.2f} kWh")
        print(f"   Total Calculation Time: {total_time:.1f}s ({total_time/60:.1f} min)")
    else:
        print(f"âŒ No vehicles processed successfully")

    # å®Œæˆæ‰€æœ‰å¤„ç†
    print("\n\n" + "="*80)
    print("="*80)
    print("âœ… All Processing Complete!")
    print(f"End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    print("="*80 + "\n")

    return 0


if __name__ == "__main__":
    exit(main())
