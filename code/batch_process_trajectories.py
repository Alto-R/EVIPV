"""
æ‰¹é‡å¤„ç†è½¨è¿¹æ•°æ® - å•GPUä¸²è¡Œè®¡ç®—

åŠŸèƒ½ï¼š
1. è‡ªåŠ¨å‘ç°è½¨è¿¹ç›®å½•ä¸­çš„é¢„å¤„ç†è½¨è¿¹æ–‡ä»¶
2. è‡ªåŠ¨è¯†åˆ«æºæœˆä»½ï¼Œå…‹éš†è½¨è¿¹åˆ°å…¨å¹´12ä¸ªæœˆ
3. ä¸ºæ¯ä¸ªæœˆä»½è·å–å¯¹åº”çš„æ°”è±¡æ•°æ®
4. è®¡ç®—å…¨å¹´12ä¸ªæœˆçš„å…‰ä¼å‘ç”µé‡
5. ä¿å­˜åˆå¹¶çš„å…¨å¹´ç»“æœåˆ°å•ä¸ªæ–‡ä»¶
6. ç”Ÿæˆæ‰¹å¤„ç†æ±‡æ€»æŠ¥å‘Š

ä½¿ç”¨ç¤ºä¾‹ï¼š
    # ä½¿ç”¨å†…éƒ¨CONFIGé…ç½®
    python batch_process_trajectories.py

    # ä½¿ç”¨å¤–éƒ¨config.yamlï¼ˆå¯é€‰ï¼‰
    python batch_process_trajectories.py --config config.yaml

    # æŒ‡å®šä½¿ç”¨GPU 0
    python batch_process_trajectories.py --gpu 0

    # è®¡ç®—è½¦è¾†èŒƒå›´ [101:200]ï¼ˆ1-basedç´¢å¼•ï¼‰
    python batch_process_trajectories.py --vehicle-range 101:200

    # è®¡ç®—ä»ç¬¬501è¾†åˆ°æœ«å°¾
    python batch_process_trajectories.py --vehicle-range 501:

    # è®¡ç®—å‰100è¾†ï¼ˆç­‰åŒäº --vehicle-range 1:100ï¼‰
    python batch_process_trajectories.py --vehicle-range :100

    # ç»„åˆä½¿ç”¨
    python batch_process_trajectories.py --config config.yaml --gpu 1 --vehicle-range 1:50
"""

import os
import sys
from pathlib import Path
import pandas as pd
import numpy as np
import trimesh
import yaml
import argparse
from datetime import datetime
import time
import gc  # åƒåœ¾å›æ”¶

print("\nğŸ“¦ æ­£åœ¨å¯¼å…¥æ¨¡å—...", flush=True)

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
print("   - å¯¼å…¥ prepare_building_mesh_from_footprint...", flush=True)
from prepare_building_mesh_from_footprint import prepare_building_mesh_from_footprint

print("   - å¯¼å…¥ fetch_irradiance_data...", flush=True)
from fetch_irradiance_data import fetch_and_cache_irradiance_data, convert_to_pvlib_format

print("   - å¯¼å…¥ pv_calculator_gpu...", flush=True)
from pv_calculator_gpu import GPUAcceleratedSolarPVCalculator

print("   âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥å®Œæˆï¼\n", flush=True)


# ============================================================================
# è¾…åŠ©å‡½æ•°
# ============================================================================
def detect_source_month(df, datetime_column='datetime'):
    """
    è‡ªåŠ¨æ£€æµ‹è½¨è¿¹æ•°æ®çš„æºæœˆä»½

    Parameters
    ----------
    df : pandas.DataFrame
        è½¨è¿¹æ•°æ®
    datetime_column : str
        æ—¥æœŸæ—¶é—´åˆ—å

    Returns
    -------
    int
        æºæœˆä»½ (1-12)
    """
    month_counts = df[datetime_column].dt.month.value_counts()
    source_month = month_counts.idxmax()
    return int(source_month)


def clone_trajectory_to_month(df, target_month, datetime_column='datetime'):
    """
    å°†è½¨è¿¹æ—¶é—´æˆ³å…‹éš†åˆ°ç›®æ ‡æœˆä»½

    Parameters
    ----------
    df : pandas.DataFrame
        åŸå§‹è½¨è¿¹æ•°æ®
    target_month : int
        ç›®æ ‡æœˆä»½ (1-12)
    datetime_column : str
        æ—¥æœŸæ—¶é—´åˆ—å

    Returns
    -------
    pandas.DataFrame
        æ—¶é—´æˆ³å·²è½¬æ¢çš„è½¨è¿¹æ•°æ®ï¼ˆè¿‡æ»¤æ‰æ— æ•ˆæ—¥æœŸï¼‰
    """
    original_dt = df[datetime_column]

    # ä¿å­˜åŸå§‹æ—¶åŒºä¿¡æ¯
    original_tz = original_dt.dt.tz

    # ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ„å»ºæ–°æ—¥æœŸ
    try:
        new_dates = pd.to_datetime({
            'year': original_dt.dt.year,
            'month': target_month,
            'day': original_dt.dt.day,
            'hour': original_dt.dt.hour,
            'minute': original_dt.dt.minute,
            'second': original_dt.dt.second,
        }, errors='coerce')
    except Exception:
        # å¦‚æœå‘é‡åŒ–å¤±è´¥ï¼Œå›é€€åˆ°applyæ–¹æ³•
        def replace_month(dt):
            try:
                return dt.replace(month=target_month)
            except ValueError:
                return pd.NaT
        new_dates = original_dt.apply(replace_month)

    # æ¢å¤æ—¶åŒºä¿¡æ¯
    if original_tz is not None:
        new_dates = new_dates.dt.tz_localize(original_tz)

    # æ‰¾å‡ºæœ‰æ•ˆæ—¥æœŸçš„è¡Œ
    valid_mask = new_dates.notna()

    # å¤åˆ¶æœ‰æ•ˆè¡Œå¹¶æ›´æ–°æ—¶é—´æˆ³
    df_cloned = df[valid_mask].copy()
    df_cloned[datetime_column] = new_dates[valid_mask]

    return df_cloned, (~valid_mask).sum()


# ============================================================================
# é…ç½®å‚æ•° - åœ¨æ­¤ä¿®æ”¹æ‚¨çš„è®¾ç½®
# ============================================================================
CONFIG = {
    'location': {
        'name': 'æ·±åœ³å¸‚',
        'lat': 22.543099,
        'lon': 114.057868,
    },
    'data_sources': {
        'footprint_path': 'data/shenzhen_buildings.geojson',
        'trajectory_dir': '../../../../data2/hcr/evipv/shenzhendata/taxi/taxi/processed',  # è½¨è¿¹æ–‡ä»¶ç›®å½•
    },
    'pv_system': {
        'panel_area': 2.2,          # å…‰ä¼æ¿é¢ç§¯(mÂ²)
        'panel_efficiency': 0.20,   # æ•ˆç‡ 20%
        'tilt': 0,                  # å€¾è§’(åº¦)
        'vehicle_height': 1.5,      # è½¦é¡¶é«˜åº¦(m)
    },
    'computation': {
        'time_resolution_minutes': 1,  # æ—¶é—´åˆ†è¾¨ç‡
        'use_gpu': True,               # å¯ç”¨GPU
        'gpu_id': 1,                   # GPUç¼–å· (0, 1, 2...), None=è‡ªåŠ¨é€‰æ‹©
        'mesh_grid_size': None,        # meshç½‘æ ¼å¤§å°(m), None=ä¸ç»†åˆ†
        'clone_to_all_months': True,   # æ˜¯å¦å…‹éš†åˆ°å…¨å¹´12ä¸ªæœˆ
        'max_vehicles': 1000,          # æœ€å¤§å¤„ç†è½¦è¾†æ•°, None=ä¸é™åˆ¶ï¼ˆè‹¥ä½¿ç”¨vehicle_rangeå°†å¿½ç•¥æ­¤å‚æ•°ï¼‰
        'vehicle_range': None,         # è½¦è¾†ç´¢å¼•åŒºé—´ï¼ˆ1-basedï¼‰ï¼Œæ ¼å¼: "èµ·å§‹:ç»“æŸ" æˆ– [èµ·å§‹, ç»“æŸ]
                                       # ç¤ºä¾‹: "101:200" è¡¨ç¤ºå¤„ç†ç¬¬101åˆ°200è¾†è½¦
                                       # "501:" è¡¨ç¤ºä»ç¬¬501è¾†åˆ°æœ«å°¾, ":100" è¡¨ç¤ºå‰100è¾†
                                       # None è¡¨ç¤ºä½¿ç”¨ max_vehicles å‚æ•°
        'vehicles_per_batch': 200,     # æ¯æ‰¹GPUåŒæ—¶å¤„ç†çš„è½¦è¾†æ•°ï¼ˆå……åˆ†åˆ©ç”¨æ˜¾å­˜ï¼‰
    },
    'output': {
        'mesh_path': 'data/shenzhen_building_mesh.ply',
        'output_dir': 'output',
    },
}


def load_config(config_path='config.yaml'):
    """
    åŠ è½½å¤–éƒ¨é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰

    å¦‚æœæä¾›config.yamlï¼Œå°†è¦†ç›–å†…éƒ¨CONFIG
    å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨å†…éƒ¨CONFIG
    """
    if Path(config_path).exists():
        print(f"ğŸ“„ åŠ è½½å¤–éƒ¨é…ç½®æ–‡ä»¶: {config_path}")
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    else:
        return None


def find_processed_trajectories(traj_dir='traj'):
    """
    æŸ¥æ‰¾æ‰€æœ‰é¢„å¤„ç†åçš„è½¨è¿¹æ–‡ä»¶

    Parameters
    ----------
    traj_dir : str
        è½¨è¿¹æ–‡ä»¶ç›®å½•

    Returns
    -------
    list
        è½¨è¿¹æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    traj_dir = Path(traj_dir)
    traj_files = list(traj_dir.glob('*_processed.csv'))

    return sorted(traj_files)


def parse_vehicle_range(range_value):
    """
    è§£æè½¦è¾†åŒºé—´é…ç½®ï¼Œæ”¯æŒå­—ç¬¦ä¸² "a:b" æˆ–é•¿åº¦ä¸º2çš„åˆ—è¡¨/å…ƒç»„
    è¿”å› (start, end)ï¼Œ1-basedç´¢å¼•ï¼Œendä¸ºNoneè¡¨ç¤ºåˆ°æœ«å°¾
    """
    if range_value is None:
        return None

    start, end = None, None

    if isinstance(range_value, str):
        if ':' not in range_value:
            raise ValueError("vehicle_range å­—ç¬¦ä¸²æ ¼å¼åº”ä¸º 'a:b'")
        start_str, end_str = range_value.split(':', 1)
        start = int(start_str) if start_str.strip() else None
        end = int(end_str) if end_str.strip() else None
    elif isinstance(range_value, (list, tuple)):
        if len(range_value) != 2:
            raise ValueError("vehicle_range åˆ—è¡¨/å…ƒç»„é•¿åº¦å¿…é¡»ä¸º2ï¼Œä¾‹å¦‚ [1, 100]")
        start = int(range_value[0]) if range_value[0] is not None else None
        end = int(range_value[1]) if range_value[1] is not None else None
    else:
        raise ValueError("vehicle_range ä»…æ”¯æŒå­—ç¬¦ä¸² 'a:b' æˆ–é•¿åº¦ä¸º2çš„åˆ—è¡¨/å…ƒç»„")

    if start is not None and start < 1:
        raise ValueError("vehicle_range èµ·å§‹ç´¢å¼•å¿…é¡»>=1")
    if end is not None and end < 1:
        raise ValueError("vehicle_range ç»“æŸç´¢å¼•å¿…é¡»>=1")

    if end is not None and start is not None and end < start:
        raise ValueError("vehicle_range ç»“æŸç´¢å¼•å¿…é¡»å¤§äºç­‰äºèµ·å§‹ç´¢å¼•")

    return start, end


def calculate_stats(result_df):
    """
    è®¡ç®—è½¨è¿¹çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ”¯æŒå…¨å¹´æ•°æ®ï¼‰

    Parameters
    ----------
    result_df : pandas.DataFrame
        è®¡ç®—ç»“æœ

    Returns
    -------
    dict
        ç»Ÿè®¡ä¿¡æ¯
    """
    stats = {
        'total_records': len(result_df),
        'total_energy_kwh': result_df['energy_kwh'].sum(),
        'avg_power_w': result_df['ac_power'].mean(),
        'max_power_w': result_df['ac_power'].max(),
        'shaded_ratio': result_df['is_shaded'].mean(),
        'avg_cell_temp': result_df['cell_temp'].mean(),
        'time_range': (result_df['datetime'].min(), result_df['datetime'].max()),
    }

    # æŒ‰æœˆç»Ÿè®¡ï¼ˆå…¨å¹´æ¨¡å¼ä¸‹monthåˆ—å¿…ç„¶å­˜åœ¨ï¼‰
    monthly_energy = result_df.groupby('month')['energy_kwh'].sum().to_dict()
    stats['monthly_energy_kwh'] = monthly_energy

    return stats


def save_batch_summary(all_stats, output_path):
    """
    ä¿å­˜æ‰¹å¤„ç†æ±‡æ€»æŠ¥å‘Š

    Parameters
    ----------
    all_stats : dict
        æ‰€æœ‰è½¦è¾†çš„ç»Ÿè®¡ä¿¡æ¯
    output_path : str or Path
        è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("="*60 + "\n")
        f.write("Batch Processing Summary - All Vehicles (Full Year)\n")
        f.write("="*60 + "\n\n")
        f.write(f"Processing Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"Total Vehicles: {len(all_stats)}\n\n")

        total_energy = sum(s['stats']['total_energy_kwh'] for s in all_stats.values())
        total_time = sum(s['elapsed_time'] for s in all_stats.values())

        f.write("Overall Summary:\n")
        f.write(f"  Total Energy (All Vehicles, Full Year): {total_energy:.2f} kWh\n")
        f.write(f"  Total Calculation Time: {total_time:.1f} seconds ({total_time/60:.1f} min)\n\n")

        # æŒ‰æœˆæ±‡æ€»ï¼ˆå…¨å¹´æ¨¡å¼ä¸‹monthly_energy_kwhå¿…ç„¶å­˜åœ¨ï¼‰
        monthly_totals = {}
        for vehicle_id, data in all_stats.items():
            for month, energy in data['stats']['monthly_energy_kwh'].items():
                monthly_totals[month] = monthly_totals.get(month, 0) + energy

        f.write("Monthly Energy Summary (All Vehicles):\n")
        for month in sorted(monthly_totals.keys()):
            f.write(f"  Month {month:02d}: {monthly_totals[month]:.2f} kWh\n")
        f.write("\n")

        f.write("Per-Vehicle Statistics:\n")
        f.write("-"*60 + "\n")

        for vehicle_id, data in all_stats.items():
            stats = data['stats']
            f.write(f"\n{vehicle_id}:\n")
            f.write(f"  Records: {stats['total_records']:,}\n")
            f.write(f"  Total Energy (Full Year): {stats['total_energy_kwh']:.2f} kWh\n")
            f.write(f"  Avg Power: {stats['avg_power_w']:.2f} W\n")
            f.write(f"  Peak Power: {stats['max_power_w']:.2f} W\n")
            f.write(f"  Shaded Ratio: {stats['shaded_ratio']*100:.1f}%\n")
            f.write(f"  Calculation Time: {data['elapsed_time']:.1f}s\n")

            # æ˜¾ç¤ºæ¯æœˆå‘ç”µé‡ï¼ˆå…¨å¹´æ¨¡å¼ä¸‹å¿…ç„¶å­˜åœ¨ï¼‰
            f.write(f"  Monthly Breakdown:\n")
            for month in sorted(stats['monthly_energy_kwh'].keys()):
                f.write(f"    Month {month:02d}: {stats['monthly_energy_kwh'][month]:.2f} kWh\n")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡å¤„ç†è½¨è¿¹æ•°æ®è®¡ç®—å…‰ä¼å‘ç”µé‡ï¼ˆå•GPUä¸²è¡Œï¼Œå…¨å¹´ç‰ˆæœ¬ï¼‰'
    )
    parser.add_argument(
        '--config', '-c',
        default=None,
        help='å¤–éƒ¨é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œä¸æŒ‡å®šåˆ™ä½¿ç”¨è„šæœ¬å†…éƒ¨CONFIGï¼‰'
    )
    parser.add_argument(
        '--gpu', '-g',
        type=int,
        default=None,
        help='æŒ‡å®šGPUç¼–å· (0, 1, 2...), ä¸æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è®¾ç½®'
    )
    parser.add_argument(
        '--vehicle-range', '-r',
        type=str,
        default=None,
        help="è½¦è¾†ç´¢å¼•åŒºé—´ï¼Œæ ¼å¼ 'a:b'ï¼ˆ1-basedï¼Œbå¯çœç•¥è¡¨ç¤ºåˆ°æœ«å°¾ï¼Œç¤ºä¾‹ï¼š--vehicle-range 101:200ï¼‰"
    )

    args = parser.parse_args()

    print("\n" + "="*80)
    print(" "*15 + "ğŸš€ Batch Vehicle PV Generation Calculation (GPU)")
    print(" "*20 + "Full Year Mode - 12 Months")
    print("="*80)
    print(f"Start Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # åŠ è½½é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨å¤–éƒ¨é…ç½®ï¼Œå¦åˆ™ä½¿ç”¨å†…éƒ¨CONFIG
    if args.config:
        external_config = load_config(args.config)
        if external_config:
            config = external_config
        else:
            print(f"âš ï¸  å¤–éƒ¨é…ç½®æ–‡ä»¶ {args.config} ä¸å­˜åœ¨ï¼Œä½¿ç”¨å†…éƒ¨CONFIG")
            config = CONFIG
    else:
        print("ğŸ“‹ ä½¿ç”¨è„šæœ¬å†…éƒ¨CONFIGé…ç½®")
        config = CONFIG

    # GPUè®¾ç½®ï¼šå‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆäºé…ç½®æ–‡ä»¶
    gpu_id = args.gpu if args.gpu is not None else config['computation'].get('gpu_id', 0)

    if config['computation']['use_gpu'] and gpu_id is not None:
        os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu_id)
        print(f"ğŸ® GPUè®¾ç½®: ä½¿ç”¨GPU {gpu_id}")
        print(f"   ç¯å¢ƒå˜é‡: CUDA_VISIBLE_DEVICES={gpu_id}")
    elif config['computation']['use_gpu']:
        print(f"ğŸ® GPUè®¾ç½®: ä½¿ç”¨é»˜è®¤GPUï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰")
    else:
        print(f"ğŸ’» GPUè®¾ç½®: GPUå·²ç¦ç”¨ï¼Œä½¿ç”¨CPU")

    # å…¨å¹´æ¨¡å¼æç¤º
    clone_to_all_months = config['computation'].get('clone_to_all_months', True)
    if clone_to_all_months:
        print(f"ğŸ“… å…¨å¹´æ¨¡å¼: å¯ç”¨ (å°†å…‹éš†è½¨è¿¹åˆ°12ä¸ªæœˆ)")
    else:
        print(f"ğŸ“… å…¨å¹´æ¨¡å¼: ç¦ç”¨ (ä»…è®¡ç®—åŸå§‹æœˆä»½)")

    # GPUå¯ç”¨æ€§æ£€æŸ¥
    if config['computation']['use_gpu']:
        try:
            import torch
            print(f"\nğŸ” GPUå¯ç”¨æ€§æ£€æŸ¥:")
            print(f"   PyTorchç‰ˆæœ¬: {torch.__version__}")
            print(f"   CUDAå¯ç”¨: {torch.cuda.is_available()}")
            if torch.cuda.is_available():
                print(f"   CUDAç‰ˆæœ¬: {torch.version.cuda}")
                print(f"   å¯ç”¨GPUæ•°é‡: {torch.cuda.device_count()}")
                print(f"   å½“å‰GPU: {torch.cuda.current_device()}")
                print(f"   GPUåç§°: {torch.cuda.get_device_name(0)}")
                print(f"   GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")

                # æµ‹è¯•GPUæ˜¯å¦çœŸçš„å¯ç”¨
                print(f"\nğŸ§ª GPUæ€§èƒ½æµ‹è¯•...")
                test_start = time.time()
                test_tensor = torch.randn(1000, 1000).cuda()
                test_result = torch.matmul(test_tensor, test_tensor)
                torch.cuda.synchronize()
                test_time = time.time() - test_start
                print(f"   âœ… GPUæµ‹è¯•æˆåŠŸ! è€—æ—¶: {test_time:.3f}s")
            else:
                print(f"   âš ï¸  è­¦å‘Š: CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®¡ç®—ï¼ˆä¼šå¾ˆæ…¢ï¼‰")
        except Exception as e:
            print(f"   âŒ GPUæ£€æŸ¥å¤±è´¥: {e}")

    print("="*80)

    # è®¾ç½®è¾“å…¥è¾“å‡ºè·¯å¾„
    traj_dir = Path(config['data_sources']['trajectory_dir'])
    output_dir = Path(config['output']['output_dir'])
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"\nğŸ“ è½¨è¿¹ç›®å½•: {traj_dir}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print("="*80)

    # å‡†å¤‡å»ºç­‘mesh
    print("\n" + "="*80)
    print("Preparing Building Mesh")
    print("="*80)

    mesh_start_time = time.time()
    mesh_path = Path(config['output']['mesh_path'])

    if mesh_path.exists():
        print(f"â±ï¸  [{datetime.now().strftime('%H:%M:%S')}] Loading existing mesh: {mesh_path}")
        building_mesh = trimesh.load(mesh_path)
        print(f"   Vertices: {len(building_mesh.vertices):,}")
        print(f"   Faces: {len(building_mesh.faces):,}")
        print(f"   âœ… MeshåŠ è½½å®Œæˆï¼Œè€—æ—¶: {time.time() - mesh_start_time:.2f}s")
    else:
        print(f"â±ï¸  [{datetime.now().strftime('%H:%M:%S')}] Converting footprint to mesh...")
        print(f"   âš ï¸  è¿™æ˜¯é¦–æ¬¡è¿è¡Œï¼Œç”Ÿæˆmeshå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼ˆæ•°åˆ†é’Ÿï¼‰...")
        building_mesh = prepare_building_mesh_from_footprint(
            footprint_path=config['data_sources']['footprint_path'],
            output_mesh_path=str(mesh_path),
            grid_size=config['computation']['mesh_grid_size']
        )
        print(f"   âœ… Meshç”Ÿæˆå®Œæˆï¼Œè€—æ—¶: {time.time() - mesh_start_time:.2f}s")

    # åˆå§‹åŒ–GPUè®¡ç®—å™¨
    print("\n" + "="*80, flush=True)
    print("Initialize GPU Calculator", flush=True)
    print("="*80, flush=True)

    calc_init_start = time.time()
    print(f"â±ï¸  [{datetime.now().strftime('%H:%M:%S')}] æ­£åœ¨åˆå§‹åŒ–GPUè®¡ç®—å™¨...", flush=True)
    print(f"   è¿™ä¸€æ­¥å¯èƒ½éœ€è¦10-30ç§’ï¼Œè¯·è€å¿ƒç­‰å¾…...", flush=True)

    calculator = GPUAcceleratedSolarPVCalculator(
        lon_center=config['location']['lon'],
        lat_center=config['location']['lat'],
        building_mesh=building_mesh,
        panel_area=config['pv_system']['panel_area'],
        panel_efficiency=config['pv_system']['panel_efficiency'],
        time_resolution_minutes=config['computation']['time_resolution_minutes'],
        use_gpu=config['computation']['use_gpu']
    )

    print(f"   âœ… GPUè®¡ç®—å™¨åˆå§‹åŒ–å®Œæˆï¼Œè€—æ—¶: {time.time() - calc_init_start:.2f}s", flush=True)

    # æŸ¥æ‰¾è½¨è¿¹æ–‡ä»¶
    print("\n" + "="*80)
    print("Step 1: Discover Trajectory Files")
    print("="*80)

    traj_files = find_processed_trajectories(traj_dir)

    if not traj_files:
        print(f"âš ï¸  No processed trajectory files found in {traj_dir}/")
        print(f"   è¯·ç¡®ä¿è½¨è¿¹æ–‡ä»¶ä»¥ '_processed.csv' ç»“å°¾")
        return 1

    print(f"âœ… Found {len(traj_files)} processed trajectory files in total")

    # è½¦è¾†ç­›é€‰ï¼šä¼˜å…ˆä½¿ç”¨ vehicle_rangeï¼Œå¦åˆ™ä½¿ç”¨ max_vehicles
    # å‘½ä»¤è¡Œå‚æ•° > é…ç½®æ–‡ä»¶
    vehicle_range_arg = args.vehicle_range if args.vehicle_range else config['computation'].get('vehicle_range', None)

    if vehicle_range_arg:
        # ä½¿ç”¨èŒƒå›´ç­›é€‰
        try:
            start_idx, end_idx = parse_vehicle_range(vehicle_range_arg)

            # ä¿å­˜åŸå§‹æ–‡ä»¶æ€»æ•°ï¼ˆç”¨äºæ˜¾ç¤ºï¼‰
            total_files = len(traj_files)

            # è½¬æ¢ä¸º0-basedç´¢å¼•
            start_0based = (start_idx - 1) if start_idx else 0
            end_0based = end_idx if end_idx else total_files

            # éªŒè¯èŒƒå›´æœ‰æ•ˆæ€§
            if start_0based < 0:
                start_0based = 0
            if end_0based > total_files:
                end_0based = total_files
            if start_0based >= total_files:
                print(f"âŒ é”™è¯¯: èµ·å§‹ç´¢å¼• {start_idx} è¶…å‡ºèŒƒå›´ï¼ˆå…± {total_files} ä¸ªæ–‡ä»¶ï¼‰")
                return 1

            traj_files = traj_files[start_0based:end_0based]
            print(f"ğŸ“Œ ä½¿ç”¨è½¦è¾†èŒƒå›´: [{start_idx if start_idx else 1}:{end_idx if end_idx else total_files}]")
            print(f"   é€‰æ‹©äº† {len(traj_files)} ä¸ªè½¦è¾†ï¼ˆç´¢å¼• {start_0based+1} åˆ° {end_0based}ï¼‰")

        except ValueError as e:
            print(f"âŒ é”™è¯¯: vehicle_range å‚æ•°æ ¼å¼é”™è¯¯ - {e}")
            return 1
    else:
        # ä½¿ç”¨ max_vehicles é™åˆ¶
        max_vehicles = config['computation'].get('max_vehicles', None)
        if max_vehicles and len(traj_files) > max_vehicles:
            print(f"âš ï¸  é™åˆ¶ä¸ºå‰ {max_vehicles} ä¸ªè½¦è¾†")
            traj_files = traj_files[:max_vehicles]
        else:
            print(f"ğŸ“Œ å¤„ç†æ‰€æœ‰ {len(traj_files)} ä¸ªè½¦è¾†")

    # æ‰¹é‡å¤„ç†è½¨è¿¹
    print("\n" + "="*80)
    print("Step 2: Process Trajectories (Full Year - Batch Mode)")
    print("="*80)
          
    all_stats = {}
    vehicles_per_batch = config['computation'].get('vehicles_per_batch', 1)

    print(f"\nâš¡ Batch Configuration:")
    print(f"   Total vehicles: {len(traj_files)}")
    print(f"   Vehicles per batch: {vehicles_per_batch}")
    print(f"   Total batches: {(len(traj_files) + vehicles_per_batch - 1) // vehicles_per_batch}")
    print(f"   Expected GPU memory saving: ~{vehicles_per_batch}x speedup\n")

    # åˆ†æ‰¹å¤„ç†è½¦è¾†
    for batch_idx in range(0, len(traj_files), vehicles_per_batch):
        batch_files = traj_files[batch_idx:batch_idx + vehicles_per_batch]
        batch_num = batch_idx // vehicles_per_batch + 1
        total_batches = (len(traj_files) + vehicles_per_batch - 1) // vehicles_per_batch

        print(f"\n{'='*80}")
        print(f"ğŸ“¦ Processing Batch {batch_num}/{total_batches} ({len(batch_files)} vehicles)")
        print('='*80)

        batch_start_time = time.time()

        # å­˜å‚¨æ‰¹æ¬¡ä¸­æ‰€æœ‰è½¦è¾†çš„æ•°æ®
        batch_trajectories = {}  # {vehicle_id: full_year_traj}

        # 1ï¸âƒ£ è¯»å–å¹¶å‡†å¤‡æ‰¹æ¬¡ä¸­æ‰€æœ‰è½¦è¾†çš„è½¨è¿¹
        for idx, traj_file in enumerate(batch_files, 1):
            vehicle_id = traj_file.stem.replace('_processed', '')

            print(f"\n--- Vehicle {batch_idx + idx}/{len(traj_files)}: {vehicle_id} ---")

            try:
                # è¯»å–è½¨è¿¹
                print(f"ğŸ“‚ Loading trajectory: {traj_file.name}", flush=True)
                trajectory_df = pd.read_csv(traj_file)
                trajectory_df['datetime'] = pd.to_datetime(trajectory_df['datetime'])

                # ç¡®ä¿æ—¶åŒºç»Ÿä¸€ä¸º Asia/Shanghai
                if trajectory_df['datetime'].dt.tz is None:
                    trajectory_df['datetime'] = trajectory_df['datetime'].dt.tz_localize('Asia/Shanghai')
                else:
                    trajectory_df['datetime'] = trajectory_df['datetime'].dt.tz_convert('Asia/Shanghai')

                print(f"   Records: {len(trajectory_df):,}", flush=True)

                # æ£€æµ‹æºæœˆä»½
                source_month = detect_source_month(trajectory_df)
                print(f"   Source Month: {source_month}", flush=True)

                # ç¡®å®šè¦å¤„ç†çš„æœˆä»½
                clone_to_all_months = config['computation'].get('clone_to_all_months', True)
                if clone_to_all_months:
                    months_to_process = list(range(1, 13))
                else:
                    months_to_process = [source_month]

                # å…‹éš†è½¨è¿¹åˆ°æ‰€æœ‰æœˆä»½
                print(f"   Cloning to {len(months_to_process)} months...", flush=True)
                all_monthly_trajs = []
                total_dropped = 0

                for target_month in months_to_process:
                    if target_month == source_month:
                        month_traj_df = trajectory_df.copy()
                        dropped_rows = 0
                    else:
                        month_traj_df, dropped_rows = clone_trajectory_to_month(
                            trajectory_df, target_month
                        )
                        total_dropped += dropped_rows

                    if len(month_traj_df) > 0:
                        month_traj_df['month'] = target_month
                        all_monthly_trajs.append(month_traj_df)

                if total_dropped > 0:
                    print(f"   âš ï¸  Dropped {total_dropped} invalid dates", flush=True)

                if not all_monthly_trajs:
                    print(f"   âš ï¸  No valid data, skipping", flush=True)
                    continue

                # åˆå¹¶å…¨å¹´æ•°æ®
                full_year_traj = pd.concat(all_monthly_trajs, ignore_index=True)

                # ğŸ”„ é‡è¦ï¼šåœ¨åˆå¹¶å‰å…ˆé‡é‡‡æ ·æ¯ä¸ªè½¦è¾†çš„è½¨è¿¹
                print(f"   ğŸ”„ Resampling trajectory ({len(full_year_traj):,} â†’ resampled)...", flush=True)
                resampled_traj = calculator.resample_trajectory(full_year_traj)

                # ğŸ”§ ä¿®å¤ï¼šresample_trajectory ç°åœ¨è¿”å› DatetimeIndexï¼Œéœ€è¦é‡ç½®ä¸ºåˆ—ä»¥ä¾¿åç»­æ“ä½œ
                resampled_traj.reset_index(inplace=True)

                # æ·»åŠ è½¦è¾†IDå’Œæœˆä»½æ ‡è¯†
                resampled_traj['vehicle_id'] = vehicle_id
                # ç›´æ¥ä»datetimeæå–æœˆä»½
                resampled_traj['month'] = resampled_traj['datetime'].dt.month

                batch_trajectories[vehicle_id] = resampled_traj

                print(f"   âœ… Prepared: {len(resampled_traj):,} records (resampled)", flush=True)

                # æ¸…ç†
                del trajectory_df, all_monthly_trajs

            except Exception as e:
                print(f"   âŒ Error preparing {vehicle_id}: {e}", flush=True)
                continue

        if not batch_trajectories:
            print(f"\nâš ï¸  No valid vehicles in this batch, skipping")
            continue

        # 2ï¸âƒ£ åˆå¹¶æ‰¹æ¬¡ä¸­æ‰€æœ‰è½¦è¾†çš„è½¨è¿¹
        print(f"\nğŸ”— Merging {len(batch_trajectories)} vehicles for batch GPU processing...")
        merged_batch_traj = pd.concat(batch_trajectories.values(), ignore_index=True)
        print(f"   Total records (all vehicles): {len(merged_batch_traj):,}")

        # æ¨æ–­æ—¥æœŸèŒƒå›´ï¼ˆå…¨æ‰¹æ¬¡ï¼‰
        start_date = merged_batch_traj['datetime'].min().strftime('%Y-%m-%d')
        end_date = merged_batch_traj['datetime'].max().strftime('%Y-%m-%d')
        print(f"   Date range: {start_date} to {end_date}")

        # 3ï¸âƒ£ è·å–å…¨å¹´æ°”è±¡æ•°æ®ï¼ˆæ‰¹æ¬¡å…±äº«ï¼‰
        print(f"\nâ˜€ï¸  Fetching full-year irradiance data...", flush=True)
        irrad_start = time.time()
        irradiance_data = fetch_and_cache_irradiance_data(
            lat=config['location']['lat'],
            lon=config['location']['lon'],
            start_date=start_date,
            end_date=end_date,
            granularity='1min' if config['computation']['time_resolution_minutes'] == 1 else '1hour',
            save_csv=False,
            output_dir='irradiance_data'
        )
        weather_data = convert_to_pvlib_format(irradiance_data)
        print(f"   âœ… Weather data ready ({time.time() - irrad_start:.1f}s)", flush=True)

        # 4ï¸âƒ£ ä¸€æ¬¡æ€§GPUè®¡ç®—æ•´ä¸ªæ‰¹æ¬¡
        print(f"\nâš¡ GPU Batch Calculation ({len(batch_trajectories)} vehicles simultaneously)...", flush=True)
        print(f"   åˆå¹¶æ•°æ®å¤§å°: {len(merged_batch_traj):,} è¡Œ", flush=True)
        print(f"   å†…å­˜ä¼°ç®—: {merged_batch_traj.memory_usage(deep=True).sum() / 1024**2:.1f} MB", flush=True)
        calc_start = time.time()

        print(f"   å¼€å§‹è°ƒç”¨ calculator.process_trajectory()...", flush=True)
        batch_result_df = calculator.process_trajectory(
            merged_batch_traj,
            weather_data=weather_data,
            skip_resample=True  # å·²åœ¨å¤–å±‚å¯¹æ¯ä¸ªè½¦è¾†å•ç‹¬é‡é‡‡æ ·
        )
        print(f"   âœ… process_trajectory è¿”å›æˆåŠŸ", flush=True)

        calc_time = time.time() - calc_start
        print(f"   âœ… Batch GPU calculation complete ({calc_time:.1f}s)", flush=True)
        print(f"   Average time per vehicle: {calc_time/len(batch_trajectories):.1f}s", flush=True)

        # 5ï¸âƒ£ éªŒè¯vehicle_idå’Œmonthä¿¡æ¯å·²åœ¨ç»“æœä¸­
        # ï¼ˆskip_resample=True åº”è¯¥ä¿è¯è¿™äº›åˆ—å­˜åœ¨ï¼‰
        assert 'vehicle_id' in batch_result_df.columns, "vehicle_idåˆ—ä¸¢å¤±ï¼Œè¯·æ£€æŸ¥process_trajectoryé€»è¾‘"
        assert 'month' in batch_result_df.columns, "monthåˆ—ä¸¢å¤±ï¼Œè¯·æ£€æŸ¥process_trajectoryé€»è¾‘"
        print(f"   âœ… vehicle_idå’Œmonthä¿¡æ¯å·²ä¿ç•™åœ¨ç»“æœä¸­")

        # 6ï¸âƒ£ æ‹†åˆ†ç»“æœå¹¶ä¿å­˜æ¯ä¸ªè½¦è¾†ï¼ˆä½¿ç”¨groupbyä¼˜åŒ–ï¼‰
        print(f"\nğŸ’¾ Splitting and saving results...")
        for vehicle_id, vehicle_result in batch_result_df.groupby('vehicle_id'):
            # ç§»é™¤ä¸´æ—¶åˆ—
            vehicle_result = vehicle_result.drop(columns=['vehicle_id'])

            # æ˜¾ç¤ºæœˆåº¦ç»Ÿè®¡ï¼ˆå…¨å¹´æ¨¡å¼ä¸‹monthåˆ—å¿…ç„¶å­˜åœ¨ï¼‰
            month_stats = []
            for month in sorted(vehicle_result['month'].unique()):
                month_energy = vehicle_result[vehicle_result['month'] == month]['energy_kwh'].sum()
                month_stats.append(f"{month:02d}:{month_energy:.1f}kWh")
            print(f"   {vehicle_id}: {', '.join(month_stats)}", flush=True)

            # ä¿å­˜ç»“æœ
            result_csv = output_dir / f"{vehicle_id}_pv_generation.csv"
            vehicle_result.to_csv(result_csv, index=False)
            file_size_mb = result_csv.stat().st_size / (1024 * 1024)

            # æ”¶é›†ç»Ÿè®¡
            stats = calculate_stats(vehicle_result)
            all_stats[vehicle_id] = {
                'stats': stats,
                'elapsed_time': calc_time / len(batch_trajectories)  # å‡æ‘Šæ—¶é—´
            }

            print(f"   âœ… {vehicle_id}: {file_size_mb:.1f}MB, {len(vehicle_result):,} records, {stats['total_energy_kwh']:.1f}kWh", flush=True)

        # æ¸…ç†æ‰¹æ¬¡æ•°æ®
        batch_elapsed = time.time() - batch_start_time
        print(f"\nâœ… Batch {batch_num} complete: {batch_elapsed:.1f}s ({batch_elapsed/len(batch_trajectories):.1f}s per vehicle)")

        del merged_batch_traj, batch_result_df, batch_trajectories, irradiance_data, weather_data
        gc.collect()

        if config['computation']['use_gpu']:
            try:
                import torch
                torch.cuda.empty_cache()
            except:
                pass


    # ä¿å­˜æ‰¹å¤„ç†æ±‡æ€»
    print("\n" + "="*80)
    print("Step 3: Generate Summary")
    print("="*80)

    if all_stats:
        # batch_summary_path = output_dir / "batch_summary.txt"
        # save_batch_summary(all_stats, batch_summary_path)
        # print(f"âœ… Batch Summary: {batch_summary_path}")

        print(f"\nğŸ“Š Processing Summary:")
        print(f"   Successfully Processed: {len(all_stats)} vehicles")
        total_energy = sum(s['stats']['total_energy_kwh'] for s in all_stats.values())
        total_time = sum(s['elapsed_time'] for s in all_stats.values())
        print(f"   Total Energy (All Vehicles, Full Year): {total_energy:.2f} kWh")
        print(f"   Total Calculation Time: {total_time:.1f}s ({total_time/60:.1f} min)")
    else:
        print(f"âŒ No vehicles processed successfully")

    # å®Œæˆæ‰€æœ‰å¤„ç†
    print("\n\n" + "="*80)
    print("="*80)
    print("âœ… All Processing Complete!")
    print(f"End Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)
    print("="*80 + "\n")

    return 0


if __name__ == "__main__":
    exit(main())
