# GPUåŠ é€Ÿç¯å¢ƒé…ç½®æŒ‡å— (Windows & Linux)

## ğŸ“‹ æ¦‚è¿°

GPUåŠ é€Ÿä¸»è¦ç”¨äºåŠ é€Ÿä»¥ä¸‹è®¡ç®—ï¼š
1. **æ‰¹é‡å…‰çº¿ç”Ÿæˆ** - ä½¿ç”¨PyTorchå¼ é‡è¿ç®—
2. **æ‰¹é‡åŠŸç‡è®¡ç®—** - ä½¿ç”¨GPUå¹¶è¡Œè®¡ç®—

**æ€§èƒ½æå‡**: CPUæ¨¡å¼ â†’ GPUæ¨¡å¼ çº¦ **8-10å€** åŠ é€Ÿ

**æ”¯æŒå¹³å°**:
- âœ… Windows 10/11
- âœ… Linux (Ubuntu 18.04+, CentOS 7+)

---

## ğŸ–¥ï¸ ç¡¬ä»¶è¦æ±‚

### å¿…éœ€ç¡¬ä»¶
- **NVIDIA GPU**: æ”¯æŒCUDAçš„æ˜¾å¡
  - æ¨è: RTX 3060 åŠä»¥ä¸Š (6GB+ æ˜¾å­˜)
  - æœ€ä½: GTX 1060 (6GB æ˜¾å­˜)
  - ä¸æ”¯æŒ: AMDæ˜¾å¡ (å½“å‰è„šæœ¬ä»…æ”¯æŒCUDA)

### æ˜¾å­˜éœ€æ±‚ä¼°ç®—

| è®¡ç®—è§„æ¨¡ | å»ºç­‘ä¸‰è§’å½¢æ•° | è½¨è¿¹ç‚¹æ•° | æ¨èæ˜¾å­˜ |
|---------|------------|---------|---------|
| å°å‹ | < 100ä¸‡ | < 1000 | 4GB |
| ä¸­å‹ | 100-500ä¸‡ | 1000-5000 | 6-8GB |
| å¤§å‹ | 500-1000ä¸‡ | 5000-10000 | 8-12GB |
| è¶…å¤§å‹ | > 1000ä¸‡ | > 10000 | 16GB+ |

---

## ğŸ’» ç¯å¢ƒé…ç½® (åˆ†å¹³å°æŒ‡å—)

### ğŸªŸ Windows ç¯å¢ƒé…ç½®

#### æ­¥éª¤1: æ£€æŸ¥NVIDIAé©±åŠ¨

```bash
# æ‰“å¼€å‘½ä»¤æç¤ºç¬¦(CMD)æˆ–PowerShell
nvidia-smi
```

**æœŸæœ›è¾“å‡º:**
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 525.60.13    Driver Version: 525.60.13    CUDA Version: 12.0   |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
|...
```

**å¦‚æœæŠ¥é”™ "nvidia-smiä¸æ˜¯å†…éƒ¨æˆ–å¤–éƒ¨å‘½ä»¤":**
1. è®¿é—®NVIDIAé©±åŠ¨ä¸‹è½½é¡µ: https://www.nvidia.com/Download/index.aspx
2. é€‰æ‹©å¯¹åº”çš„æ˜¾å¡å‹å·å’ŒWindowsç‰ˆæœ¬
3. ä¸‹è½½å¹¶å®‰è£…é©±åŠ¨ (å»ºè®®é€‰æ‹© "Game Ready Driver")
4. **é‡å¯ç”µè„‘**
5. é‡æ–°è¿è¡Œ `nvidia-smi` éªŒè¯

#### æ­¥éª¤2: å®‰è£…CUDA Toolkit (å¯é€‰)

**æ³¨æ„**: PyTorchè‡ªå¸¦CUDAè¿è¡Œåº“ï¼Œ**é€šå¸¸ä¸éœ€è¦å•ç‹¬å®‰è£…CUDA Toolkit**

**å¦‚æœéœ€è¦æ‰‹åŠ¨å®‰è£… (é«˜çº§ç”¨æˆ·):**
1. è®¿é—®: https://developer.nvidia.com/cuda-downloads
2. é€‰æ‹©: `Windows` â†’ `x86_64` â†’ `10/11` â†’ `exe (local)`
3. æ¨èç‰ˆæœ¬: **CUDA 11.8** (å…¼å®¹æ€§æœ€å¥½)
4. ä¸‹è½½å¹¶å®‰è£… (çº¦3GB)
5. éªŒè¯å®‰è£…:
   ```bash
   nvcc --version
   ```

#### æ­¥éª¤3: åˆ›å»ºPythonç¯å¢ƒ (æ¨èä½¿ç”¨Conda)

```bash
# æ‰“å¼€Anaconda Prompt

# åˆ›å»ºæ–°ç¯å¢ƒ
conda create -n pv_gpu python=3.9
conda activate pv_gpu

# æˆ–ä½¿ç”¨venv
python -m venv pv_gpu_env
pv_gpu_env\Scripts\activate
```

#### æ­¥éª¤4: å®‰è£…PyTorch (CUDAç‰ˆæœ¬)

**æ–¹æ³•A: æ¨èå®‰è£… (CUDA 11.8)**

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**æ–¹æ³•B: ä½¿ç”¨Condaå®‰è£…**

```bash
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
```

#### æ­¥éª¤5: å®‰è£…é¡¹ç›®ä¾èµ–

```bash
pip install pyvista pandas numpy geopandas pvlib-python pyproj pyyaml tqdm trimesh
```

---

### ğŸ§ Linux ç¯å¢ƒé…ç½®

#### æ­¥éª¤1: æ£€æŸ¥NVIDIAé©±åŠ¨

```bash
nvidia-smi
```

**å¦‚æœæœªå®‰è£…é©±åŠ¨:**

**Ubuntu/Debian:**
```bash
# æ–¹æ³•1: ä½¿ç”¨ubuntu-drivers (æ¨è)
sudo ubuntu-drivers autoinstall

# æ–¹æ³•2: æ‰‹åŠ¨å®‰è£…
sudo apt update
sudo apt install nvidia-driver-525  # æˆ–å…¶ä»–ç‰ˆæœ¬å·

# é‡å¯ç³»ç»Ÿ
sudo reboot

# éªŒè¯å®‰è£…
nvidia-smi
```

**CentOS/RHEL:**
```bash
# æ·»åŠ NVIDIAä»“åº“
sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo

# å®‰è£…é©±åŠ¨
sudo dnf install nvidia-driver

# é‡å¯ç³»ç»Ÿ
sudo reboot

# éªŒè¯å®‰è£…
nvidia-smi
```

**ä»æºä»£ç å®‰è£… (é€šç”¨æ–¹æ³•):**
```bash
# ä¸‹è½½é©±åŠ¨
wget https://us.download.nvidia.com/XFree86/Linux-x86_64/525.60.13/NVIDIA-Linux-x86_64-525.60.13.run

# å®‰è£…ä¾èµ–
sudo apt install build-essential  # Ubuntu
# æˆ–
sudo yum groupinstall "Development Tools"  # CentOS

# å®‰è£…é©±åŠ¨
sudo bash NVIDIA-Linux-x86_64-525.60.13.run

# é‡å¯
sudo reboot
```

#### æ­¥éª¤2: å®‰è£…CUDA Toolkit (å¯é€‰ä½†æ¨è)

**Ubuntu:**
```bash
# æ·»åŠ CUDAä»“åº“
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin
sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600
wget https://developer.download.nvidia.com/compute/cuda/12.0.0/local_installers/cuda-repo-ubuntu2004-12-0-local_12.0.0-525.60.13-1_amd64.deb
sudo dpkg -i cuda-repo-ubuntu2004-12-0-local_12.0.0-525.60.13-1_amd64.deb
sudo cp /var/cuda-repo-ubuntu2004-12-0-local/cuda-*-keyring.gpg /usr/share/keyrings/
sudo apt-get update
sudo apt-get -y install cuda

# æˆ–è€…å®‰è£…ç‰¹å®šç‰ˆæœ¬ (æ¨èCUDA 11.8)
sudo apt-get install cuda-11-8
```

**è®¾ç½®ç¯å¢ƒå˜é‡:**
```bash
# ç¼–è¾‘ ~/.bashrc æˆ– ~/.zshrc
echo 'export PATH=/usr/local/cuda/bin:$PATH' >> ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc

# éªŒè¯å®‰è£…
nvcc --version
```

#### æ­¥éª¤3: åˆ›å»ºPythonè™šæ‹Ÿç¯å¢ƒ

**ä½¿ç”¨venv:**
```bash
# å®‰è£…venv (å¦‚æœæœªå®‰è£…)
sudo apt install python3-venv python3-pip  # Ubuntu
# æˆ–
sudo yum install python3-venv python3-pip  # CentOS

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv ~/pv_gpu_env
source ~/pv_gpu_env/bin/activate
```

**ä½¿ç”¨Conda (æ¨è):**
```bash
# ä¸‹è½½å¹¶å®‰è£…Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# åˆ›å»ºç¯å¢ƒ
conda create -n pv_gpu python=3.9
conda activate pv_gpu
```

#### æ­¥éª¤4: å®‰è£…PyTorch (CUDAç‰ˆæœ¬)

```bash
# ä½¿ç”¨pip (æ¨è)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# æˆ–ä½¿ç”¨conda
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia
```

#### æ­¥éª¤5: å®‰è£…é¡¹ç›®ä¾èµ–

```bash
# æ›´æ–°pip
pip install --upgrade pip

# å®‰è£…ä¾èµ–
pip install pyvista pandas numpy geopandas pvlib-python pyproj pyyaml tqdm trimesh

# å¦‚æœé‡åˆ°ç¼–è¯‘é”™è¯¯ï¼Œå®‰è£…å¼€å‘å·¥å…·
sudo apt install build-essential python3-dev  # Ubuntu
# æˆ–
sudo yum groupinstall "Development Tools" python3-devel  # CentOS
```

---

## ğŸ§ª éªŒè¯GPUå®‰è£… (é€šç”¨)

### åˆ›å»ºæµ‹è¯•è„šæœ¬

åˆ›å»º `test_gpu.py` æ–‡ä»¶:

```python
import torch
import sys

print("="*60)
print("PyTorch GPUç¯å¢ƒæ£€æµ‹")
print("="*60)

# PyTorchç‰ˆæœ¬
print(f"\nPyTorchç‰ˆæœ¬: {torch.__version__}")

# CUDAæ˜¯å¦å¯ç”¨
cuda_available = torch.cuda.is_available()
print(f"CUDAå¯ç”¨: {cuda_available}")

if cuda_available:
    # CUDAç‰ˆæœ¬
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")

    # GPUæ•°é‡
    gpu_count = torch.cuda.device_count()
    print(f"GPUæ•°é‡: {gpu_count}")

    # GPUä¿¡æ¯
    for i in range(gpu_count):
        print(f"\nGPU {i}:")
        print(f"  åç§°: {torch.cuda.get_device_name(i)}")
        props = torch.cuda.get_device_properties(i)
        print(f"  æ€»æ˜¾å­˜: {props.total_memory / 1024**3:.1f} GB")
        print(f"  è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}")

    # æµ‹è¯•GPUè®¡ç®—
    print("\næµ‹è¯•GPUè®¡ç®—...")
    try:
        x = torch.randn(1000, 1000).cuda()
        y = torch.randn(1000, 1000).cuda()
        z = torch.matmul(x, y)
        print("âœ… GPUè®¡ç®—æµ‹è¯•æˆåŠŸ")
    except Exception as e:
        print(f"âŒ GPUè®¡ç®—æµ‹è¯•å¤±è´¥: {e}")
else:
    print("\nâš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
    print("   å¦‚æœæ‚¨æœ‰NVIDIA GPUï¼Œè¯·æ£€æŸ¥:")
    print("   1. NVIDIAé©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…")
    print("   2. PyTorchæ˜¯å¦å®‰è£…äº†CUDAç‰ˆæœ¬")
    print("   3. ä½¿ç”¨å‘½ä»¤: pip install torch --index-url https://download.pytorch.org/whl/cu118")

print("="*60)
```

è¿è¡Œæµ‹è¯•:

```bash
python test_gpu.py
```

**æœŸæœ›è¾“å‡º (GPUå¯ç”¨):**
```
============================================================
PyTorch GPUç¯å¢ƒæ£€æµ‹
============================================================

PyTorchç‰ˆæœ¬: 2.1.0+cu118
CUDAå¯ç”¨: True
CUDAç‰ˆæœ¬: 11.8
GPUæ•°é‡: 1

GPU 0:
  åç§°: NVIDIA GeForce RTX 3080
  æ€»æ˜¾å­˜: 10.0 GB
  è®¡ç®—èƒ½åŠ›: 8.6

æµ‹è¯•GPUè®¡ç®—...
âœ… GPUè®¡ç®—æµ‹è¯•æˆåŠŸ
============================================================
```

---

## ğŸ”§ é…ç½®è„šæœ¬ä½¿ç”¨GPU

### æ–¹æ³•1: åœ¨é…ç½®æ–‡ä»¶ä¸­å¯ç”¨

ç¼–è¾‘ `config.yaml`:

```yaml
computation:
  use_gpu: true        # å¯ç”¨GPU
  batch_size: 100      # æ‰¹å¤„ç†å¤§å° (æ ¹æ®æ˜¾å­˜è°ƒæ•´)
```

### æ–¹æ³•2: å‘½ä»¤è¡Œå‚æ•°

```bash
# å¯ç”¨GPU (é»˜è®¤)
python main_pv_calculation_gpu.py --config config.yaml

# ç¦ç”¨GPU (å¼ºåˆ¶ä½¿ç”¨CPU)
python main_pv_calculation_gpu.py --config config.yaml --no-gpu
```

---

## âš™ï¸ æ€§èƒ½è°ƒä¼˜

### è°ƒæ•´æ‰¹å¤„ç†å¤§å° (batch_size)

æ ¹æ®æ˜¾å­˜å¤§å°è°ƒæ•´ `batch_size`:

| æ˜¾å­˜ | æ¨èbatch_size | è¯´æ˜ |
|-----|---------------|------|
| 4GB | 20-50 | å°æ‰¹é‡å¤„ç† |
| 6GB | 50-100 | ä¸­ç­‰æ‰¹é‡ |
| 8GB | 100-200 | å¤§æ‰¹é‡ |
| 12GB+ | 200-500 | è¶…å¤§æ‰¹é‡ |

**å¦‚æœé‡åˆ° "CUDA out of memory" é”™è¯¯:**

```yaml
computation:
  batch_size: 50  # å‡å°æ‰¹å¤„ç†å¤§å°
```

### ç›‘æ§æ˜¾å­˜ä½¿ç”¨

**Windows (PowerShell):**

```powershell
# æŒç»­ç›‘æ§
while($true) {
    Clear-Host
    nvidia-smi
    Start-Sleep -Seconds 1
}
```

**Linux/Windows (æ–°ç»ˆç«¯):**
```bash
# Linux
watch -n 1 nvidia-smi

# Windows Git Bash
while true; do clear; nvidia-smi; sleep 1; done
```

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜1: "CUDA not available"

**å¯èƒ½åŸå› :**
1. æœªå®‰è£…NVIDIAé©±åŠ¨
2. å®‰è£…äº†CPUç‰ˆæœ¬çš„PyTorch
3. CUDAç‰ˆæœ¬ä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ (Windows):**
```bash
# å¸è½½æ—§ç‰ˆæœ¬
pip uninstall torch torchvision torchaudio

# é‡æ–°å®‰è£…CUDAç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**è§£å†³æ–¹æ¡ˆ (Linux):**
```bash
# å¸è½½æ—§ç‰ˆæœ¬
pip uninstall torch torchvision torchaudio

# é‡æ–°å®‰è£…
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å¦‚æœä»ç„¶ä¸è¡Œï¼Œæ£€æŸ¥LD_LIBRARY_PATH
echo $LD_LIBRARY_PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
```

### é—®é¢˜2: "CUDA out of memory"

**è§£å†³æ–¹æ¡ˆ:**
1. å‡å° `batch_size`
2. ç®€åŒ–å»ºç­‘mesh (å‡å°‘ä¸‰è§’å½¢æ•°)
3. åˆ†æ‰¹å¤„ç†è½¨è¿¹æ•°æ®

```yaml
# ä¿®æ”¹ config.yaml
computation:
  batch_size: 50  # ä»100å‡å°åˆ°50
```

```python
# åœ¨è„šæœ¬ä¸­æ‰‹åŠ¨é‡Šæ”¾æ˜¾å­˜
import torch
torch.cuda.empty_cache()
```

### é—®é¢˜3: Linuxä¸‹æ‰¾ä¸åˆ°libcudart.so

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æŸ¥æ‰¾CUDAåº“è·¯å¾„
find /usr -name "libcudart.so*" 2>/dev/null

# æ·»åŠ åˆ°LD_LIBRARY_PATH
export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH

# æ°¸ä¹…æ·»åŠ åˆ° ~/.bashrc
echo 'export LD_LIBRARY_PATH=/usr/local/cuda-11.8/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
source ~/.bashrc
```

### é—®é¢˜4: Windowsä¸‹GPUåˆ©ç”¨ç‡å¾ˆä½

**å¯èƒ½åŸå› :**
- æ‰¹å¤„ç†å¤§å°å¤ªå°
- æ•°æ®ä¼ è¾“æˆä¸ºç“¶é¢ˆ
- ç”µæºç®¡ç†é™åˆ¶

**è§£å†³æ–¹æ¡ˆ:**
```bash
# è®¾ç½®Windowsé«˜æ€§èƒ½æ¨¡å¼
powercfg /setactive 8c5e7fda-e8bf-4a96-9a85-a6e23a8c635c

# å¢å¤§batch_size
# ä¿®æ”¹ config.yaml
computation:
  batch_size: 200  # æ ¹æ®æ˜¾å­˜è°ƒæ•´
```

### é—®é¢˜5: Linuxæƒé™é—®é¢˜

**è§£å†³æ–¹æ¡ˆ:**
```bash
# æ·»åŠ ç”¨æˆ·åˆ°videoç»„
sudo usermod -a -G video $USER

# é‡æ–°ç™»å½•æˆ–æ‰§è¡Œ
newgrp video

# éªŒè¯
groups
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯• (é€šç”¨)

```python
# benchmark_gpu.py
import time
import torch
import numpy as np

def benchmark_gpu_vs_cpu():
    print("GPU vs CPU æ€§èƒ½æµ‹è¯•")
    print("="*60)

    # æµ‹è¯•å‚æ•°
    n_rays = 1000000  # 100ä¸‡æ¡å…‰çº¿

    # CPUæµ‹è¯•
    print("\nCPUæµ‹è¯•...")
    origins = np.random.randn(n_rays, 3).astype(np.float32)
    directions = np.random.randn(n_rays, 3).astype(np.float32)

    start = time.time()
    result_cpu = origins - directions * 5e5
    cpu_time = time.time() - start
    print(f"  è€—æ—¶: {cpu_time:.3f} ç§’")

    # GPUæµ‹è¯•
    if torch.cuda.is_available():
        print("\nGPUæµ‹è¯•...")
        origins_gpu = torch.from_numpy(origins).cuda()
        directions_gpu = torch.from_numpy(directions).cuda()

        torch.cuda.synchronize()
        start = time.time()
        result_gpu = origins_gpu - directions_gpu * 5e5
        torch.cuda.synchronize()
        gpu_time = time.time() - start
        print(f"  è€—æ—¶: {gpu_time:.3f} ç§’")

        speedup = cpu_time / gpu_time
        print(f"\nåŠ é€Ÿæ¯”: {speedup:.1f}x")
    else:
        print("\nGPUä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")

    print("="*60)

if __name__ == "__main__":
    benchmark_gpu_vs_cpu()
```

è¿è¡Œ:
```bash
python benchmark_gpu.py
```

---

## ğŸ“ å¿«é€Ÿé…ç½®å‘½ä»¤ (å¤åˆ¶ç²˜è´´)

### Windows å¿«é€Ÿé…ç½®

```bash
# 1. æ£€æŸ¥NVIDIAé©±åŠ¨
nvidia-smi

# 2. åˆ›å»ºcondaç¯å¢ƒ
conda create -n pv_gpu python=3.9 -y
conda activate pv_gpu

# 3. å®‰è£…PyTorch (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 4. å®‰è£…é¡¹ç›®ä¾èµ–
pip install pyvista pandas numpy geopandas pvlib-python pyproj pyyaml tqdm trimesh

# 5. éªŒè¯GPU
python test_gpu.py
```

### Linux å¿«é€Ÿé…ç½® (Ubuntu/Debian)

```bash
# 1. å®‰è£…NVIDIAé©±åŠ¨
sudo ubuntu-drivers autoinstall
sudo reboot

# 2. éªŒè¯é©±åŠ¨
nvidia-smi

# 3. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
conda create -n pv_gpu python=3.9 -y
conda activate pv_gpu

# 4. å®‰è£…PyTorch (CUDA 11.8)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 5. å®‰è£…é¡¹ç›®ä¾èµ–
pip install pyvista pandas numpy geopandas pvlib-python pyproj pyyaml tqdm trimesh

# 6. éªŒè¯GPU
python test_gpu.py
```

### Linux å¿«é€Ÿé…ç½® (CentOS/RHEL)

```bash
# 1. å®‰è£…NVIDIAé©±åŠ¨
sudo dnf config-manager --add-repo https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo
sudo dnf install nvidia-driver -y
sudo reboot

# 2. éªŒè¯é©±åŠ¨
nvidia-smi

# 3. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv ~/pv_gpu_env
source ~/pv_gpu_env/bin/activate

# 4. å®‰è£…PyTorch
pip install --upgrade pip
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# 5. å®‰è£…é¡¹ç›®ä¾èµ–
pip install pyvista pandas numpy geopandas pvlib-python pyproj pyyaml tqdm trimesh

# 6. éªŒè¯GPU
python test_gpu.py
```

---

## ğŸ¯ æ¨èé…ç½®

### æœ€ä½³æ€§èƒ½é…ç½® (RTX 3080, 10GBæ˜¾å­˜)

```yaml
computation:
  use_gpu: true
  batch_size: 200
  time_resolution_minutes: 1
```

### ä½æ˜¾å­˜é…ç½® (GTX 1060, 6GBæ˜¾å­˜)

```yaml
computation:
  use_gpu: true
  batch_size: 50
  time_resolution_minutes: 5  # é™ä½æ—¶é—´åˆ†è¾¨ç‡
```

### CPUå¤‡ç”¨é…ç½® (æ— GPU)

```yaml
computation:
  use_gpu: false
  batch_size: 10
  time_resolution_minutes: 5
```

---

## âœ… æ€»ç»“

### GPUåŠ é€Ÿçš„ä¼˜åŠ¿

- âœ… è®¡ç®—é€Ÿåº¦æå‡ 8-10å€
- âœ… æ”¯æŒæ›´é«˜æ—¶é—´åˆ†è¾¨ç‡ (1åˆ†é’Ÿ)
- âœ… å¯å¤„ç†æ›´å¤§è§„æ¨¡æ•°æ®

### GPUåŠ é€Ÿçš„è¦æ±‚

- âœ… NVIDIA GPU (æ”¯æŒCUDA)
- âœ… æ­£ç¡®çš„é©±åŠ¨å’ŒPyTorchç‰ˆæœ¬
- âœ… è¶³å¤Ÿçš„æ˜¾å­˜

### å¦‚æœæ²¡æœ‰GPU

- âœ… è„šæœ¬ä¼šè‡ªåŠ¨å›é€€åˆ°CPUæ¨¡å¼
- âœ… æ‰€æœ‰åŠŸèƒ½ä¾ç„¶å¯ç”¨
- âš ï¸ è®¡ç®—é€Ÿåº¦è¾ƒæ…¢ï¼Œå»ºè®®é™ä½æ—¶é—´åˆ†è¾¨ç‡

---

## ğŸ“ æ•…éšœæ’æŸ¥æ£€æŸ¥æ¸…å•

é‡åˆ°é—®é¢˜æ—¶ï¼ŒæŒ‰é¡ºåºæ£€æŸ¥ï¼š

**1. æ£€æŸ¥NVIDIAé©±åŠ¨**

```bash
nvidia-smi
```

**2. æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨**

```bash
python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"
```

**3. æ£€æŸ¥PyTorchç‰ˆæœ¬**

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
```

**4. æ£€æŸ¥CUDAç‰ˆæœ¬åŒ¹é…**

```bash
python -c "import torch; print(f'CUDAç‰ˆæœ¬: {torch.version.cuda}')"
```

**5. Linuxç‰¹æœ‰: æ£€æŸ¥åº“è·¯å¾„**

```bash
echo $LD_LIBRARY_PATH
ldconfig -p | grep cuda
```

---

## ğŸ†˜ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜æ—¶ï¼Œè¯·æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

1. **ç³»ç»Ÿä¿¡æ¯**
   - æ“ä½œç³»ç»Ÿ: Windows/Linuxç‰ˆæœ¬
   - GPUå‹å·: `nvidia-smi` è¾“å‡º

2. **è½¯ä»¶ä¿¡æ¯**
   - Pythonç‰ˆæœ¬: `python --version`
   - PyTorchç‰ˆæœ¬: `python test_gpu.py` è¾“å‡º

3. **å®Œæ•´é”™è¯¯ä¿¡æ¯**
   - æˆªå›¾æˆ–å¤åˆ¶å®Œæ•´çš„é”™è¯¯å †æ ˆ

---

## ğŸ“š ç›¸å…³èµ„æº

- **PyTorchå®‰è£…**: https://pytorch.org/get-started/locally/
- **NVIDIAé©±åŠ¨ä¸‹è½½**: https://www.nvidia.com/Download/index.aspx
- **CUDA Toolkit**: https://developer.nvidia.com/cuda-downloads
- **é¡¹ç›®æ–‡æ¡£**: å‚è§ `README.md`

---

ç¥æ‚¨ä½¿ç”¨é¡ºåˆ©ï¼ğŸš€

å¦‚æœ‰é—®é¢˜ï¼Œæ¬¢è¿æIssueæˆ–è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚
